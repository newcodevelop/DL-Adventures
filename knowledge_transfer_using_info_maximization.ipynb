{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "knowledge transfer using info maximization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO1S2hyXrKMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!Author :- Dibyanayan Bandyopadhyay\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOSho0irrKOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c191d1b5-71a0-4a74-d433-314a75f22c09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTab8a1lrKTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "file = '/content/gdrive/My Drive/multilingual grounded/final.csv'\n",
        "df = pd.read_csv(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj9t8h9brKaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = list(df['gold_label'])\n",
        "labs = []\n",
        "for i in labels:\n",
        "    if i=='contradiction':\n",
        "        labs.append(0)\n",
        "        \n",
        "    elif i=='neutral':\n",
        "        labs.append(1)\n",
        "    elif i== 'entailment':\n",
        "        labs.append(2)\n",
        "    else:\n",
        "        labs.append(3)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfBSFYMrKeZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c243d53c-aa25-472f-bcfb-f56e90d88d49"
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQZ12NpIth20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "\n",
        "#tf.keras.backend.set_session(sess)\n",
        "tf.debugging.set_log_device_placement(True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_m5b9enrKil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab = tf.keras.utils.to_categorical(labs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMh30fm3rKg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "premises,premises_hindi,hypos_hindi,hypos  = list(df['premise']),list(df['premise_hindi']),list(df['hypo_hindi']),list(df['hypo'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewsDYx5LrKdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sen1,sen2,sen3,sen4 = [],[],[],[]\n",
        "\n",
        "for i in premises:\n",
        "    sen1.append(tf.keras.preprocessing.text.text_to_word_sequence(i))\n",
        "    \n",
        "for i in hypos:\n",
        "    sen2.append(tf.keras.preprocessing.text.text_to_word_sequence(i))\n",
        "    \n",
        "for i in premises_hindi:\n",
        "    sen3.append(tf.keras.preprocessing.text.text_to_word_sequence(i))\n",
        "    \n",
        "for i in hypos_hindi:\n",
        "    sen4.append(tf.keras.preprocessing.text.text_to_word_sequence(i))\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdEaLZK2rKYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "19996818-493e-4e15-dd9b-617c906cc404"
      },
      "source": [
        "max_len_prem = 0 #...................... max length of english premise sentence\n",
        "for i in sen1:\n",
        "    if len(i)>max_len_prem:\n",
        "        max_len_prem = len(i)\n",
        "print(max_len_prem)\n",
        "\n",
        "max_len_hypo = 0 #....................... max length of english hypothesis sentence\n",
        "for i in sen2:\n",
        "    if len(i)>max_len_hypo:\n",
        "        max_len_hypo = len(i)\n",
        "print(max_len_hypo)\n",
        "\n",
        "max_len_prem_ = 0 # max length of hindi premise sentences\n",
        "for i in sen3:\n",
        "    if len(i)>max_len_prem_:\n",
        "        max_len_prem_ = len(i)\n",
        "print(max_len_prem_)\n",
        "\n",
        "max_len_hypo_ = 0 # max length of hindi hypothesis sentences\n",
        "for i in sen4:\n",
        "    if len(i)>max_len_hypo_:\n",
        "        max_len_hypo_ = len(i)\n",
        "print(max_len_hypo_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n",
            "39\n",
            "95\n",
            "47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEbXHjsBrgsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "premises = sen1 #english prem\n",
        "hypos = sen2 #english hypo\n",
        "premises_ = sen3 #hindi premises\n",
        "hypos_ = sen4 # hindi hypos\n",
        "\n",
        "for sentences in range(len(premises)):\n",
        "    #print(sentences)\n",
        "    length = len(premises[sentences])\n",
        "    max_len = max_len_prem\n",
        "    diff = max_len-length\n",
        "    for i in range(diff):\n",
        "        premises[sentences].append('nan') # appending 'nan' token to english premises to make length of every sentences same\n",
        "\n",
        "for sentences in range(len(hypos)):\n",
        "    #print(sentences)\n",
        "    length = len(hypos[sentences])\n",
        "    max_len = max_len_hypo\n",
        "    diff = max_len-length\n",
        "    for i in range(diff):\n",
        "        hypos[sentences].append('nan')  # appending 'nan' token to english hypos to make length of every sentences same\n",
        "\n",
        "for sentences in range(len(premises_)):\n",
        "    #print(sentences)\n",
        "    length = len(premises_[sentences])\n",
        "    max_len = max_len_prem_\n",
        "    diff = max_len-length\n",
        "    for i in range(diff):\n",
        "        premises_[sentences].append('nan')  # appending 'nan' token to hindi premises to make length of every sentences same\n",
        "\n",
        "for sentences in range(len(hypos_)):\n",
        "    #print(sentences)\n",
        "    length = len(hypos_[sentences])\n",
        "    max_len = max_len_hypo_\n",
        "    diff = max_len-length\n",
        "    for i in range(diff):\n",
        "        hypos_[sentences].append('nan')  # appending 'nan' token to hindi hypos to make length of every sentences same"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16wc6wi9rgxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# generating padded docs to input in subsequent embedding layer\n",
        "def generate_padded_docs(sentences):\n",
        "    docs = sentences\n",
        "  \n",
        "    tok  = tf.keras.preprocessing.text.Tokenizer()\n",
        "    tok.fit_on_texts(docs)\n",
        "    docs = tok.texts_to_sequences(docs)\n",
        "    #print(docs)\n",
        "    max_len_multi = 0\n",
        "    for i in docs:\n",
        "        if len(i)>max_len_multi:\n",
        "            max_len_multi = len(i)\n",
        "    #print(max_len_multi)\n",
        "    padded_docs = tf.keras.preprocessing.sequence.pad_sequences(docs, maxlen=max_len_multi, padding='post')\n",
        "    vocab_size = max([max(i) for i in padded_docs])\n",
        "    return padded_docs,max_len_multi,vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLtHGzz8rg1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating padded docs from english premises and hypothesis\n",
        "padded_docs_prem,max_len_multi_prem,vocab_size_prem = generate_padded_docs(premises)\n",
        "padded_docs_hypo,max_len_multi_hypo,vocab_size_hypo = generate_padded_docs(hypos)\n",
        "\n",
        "padded_docs_prem = np.asarray(padded_docs_prem,dtype = np.int32)\n",
        "padded_docs_hypo = np.asarray(padded_docs_hypo,dtype = np.int32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1AVvB3Xrg4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generating padded docs from hindi premises and hypothesis\n",
        "padded_docs_prem_,max_len_multi_prem_,vocab_size_prem_ = generate_padded_docs(premises_)\n",
        "padded_docs_hypo_,max_len_multi_hypo_,vocab_size_hypo_ = generate_padded_docs(hypos_)\n",
        "\n",
        "padded_docs_prem_ = np.asarray(padded_docs_prem_,dtype = np.int32)\n",
        "padded_docs_hypo_ = np.asarray(padded_docs_hypo_,dtype = np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4a_GX-crg0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7b0f4162-b4ed-4696-dbe4-dbc8a15a957b"
      },
      "source": [
        "# this keras model will be used to train english and hindi model using embedding generated above (no w2v)  and without other language's contxt\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "with strategy.scope():\n",
        "  class MyModel1(tf.keras.Model):\n",
        "      def __init__(self,word_vector_length,max_len_multi_prem,max_len_multi_hypo,vocab_size_prem,vocab_size_hypo):\n",
        "          super(MyModel1, self).__init__()\n",
        "          self.lstm_shared = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(40,return_sequences = False,kernel_initializer = tf.keras.initializers.lecun_normal(seed=None),unit_forget_bias = True, name = 'lstm_main_1'),name = 'bid_1',merge_mode = 'mul')\n",
        "          self.d1 = tf.keras.layers.Dense(10, activation='relu')\n",
        "          self.d2 = tf.keras.layers.Dense(4, activation='softmax')\n",
        "      \n",
        "          self.word_vector_length = word_vector_length\n",
        "          self.max_len_multi_prem = max_len_multi_prem\n",
        "          self.max_len_multi_hypo = max_len_multi_hypo\n",
        "          self.vocab_size_prem = vocab_size_prem\n",
        "          self.vocab_size_hypo = vocab_size_hypo\n",
        "          self.embedding1 = tf.keras.layers.Embedding(self.vocab_size_prem+1, self.word_vector_length, input_length=self.max_len_multi_prem)\n",
        "          self.embedding2 = tf.keras.layers.Embedding(self.vocab_size_hypo+1, self.word_vector_length ,input_length=self.max_len_multi_hypo)\n",
        "      def call(self,inputs):\n",
        "        \n",
        "          h1 = self.embedding1(inputs[0])\n",
        "          x= self.lstm_shared(h1)\n",
        "          #h1 = tf.nn.embedding_lookup(self.word_embeddings, inputs[1])#inputs[1] is padded_docs\n",
        "          h2 = self.embedding2(inputs[1])\n",
        "          print(np.shape(h1))\n",
        "          \n",
        "          y = self.lstm_shared(h2)\n",
        "          z = tf.math.abs(x-y)\n",
        "\n",
        "          \n",
        "          z = self.d1(z)\n",
        "          return self.d2(z)\n",
        "    # training on first 35k data of english language\n",
        "  model1 = MyModel1(30,max_len_multi_prem,max_len_multi_hypo,vocab_size_prem,vocab_size_hypo)\n",
        "  model1.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  model1.fit([padded_docs_prem[0:35000,:],padded_docs_hypo[0:35000,:]],[np.asarray(lab[0:35000,:],dtype=np.int32)],epochs = 2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method MyModel1.call of <__main__.MyModel1 object at 0x7f5841e22c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MyModel1.call of <__main__.MyModel1 object at 0x7f5841e22c18>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Qr in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sign in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Transpose in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(?, 78, 30)\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op UnbatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ConcatenateDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DatasetCardinality in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RebatchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AutoShardDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Train on 35000 samples\n",
            "Epoch 1/2\n",
            "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorInit in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MultiDeviceIteratorToStringHandle in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op GeneratorDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(?, 78, 30)\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f57cbea9b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f57cbea9b70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Executing op __inference_initialize_variables_7663 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(?, 78, 30)\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Executing op __inference_distributed_function_13457 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "35000/35000 [==============================] - 477s 14ms/sample - loss: 1.0537 - acc: 0.4305\n",
            "Epoch 2/2\n",
            "35000/35000 [==============================] - 447s 13ms/sample - loss: 0.9052 - acc: 0.5750\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVFUGaLArKXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "563a6620-4f20-4b52-dedf-3bad83137630"
      },
      "source": [
        "x = model1.lstm_shared(model1.embedding1(padded_docs_prem))\n",
        "y = model1.lstm_shared(model1.embedding2(padded_docs_hypo))\n",
        "z = tf.math.abs(x-y)\n",
        "print(z)\n",
        "#print(np.sum(z_,axis = 1))\n",
        "#print(np.sum(tf.keras.activations.softmax(z_),axis = 1))\n",
        "z_ = model1.d1(z)\n",
        "fin = model1.d2(z_)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(np.argmax(fin[35000:,:],axis = 1),np.argmax(lab[35000:,:],axis = 1)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.86744726 0.6140226  0.01665686 ... 0.96878815 0.27091035 0.52119684]\n",
            " [0.50891733 0.4197212  0.01676336 ... 0.92155373 0.22085156 0.64875454]\n",
            " [0.30674678 0.06245703 0.01667597 ... 0.89776754 0.1934443  0.8124353 ]\n",
            " ...\n",
            " [0.29280323 0.0628469  0.01145307 ... 0.75601965 0.24875158 0.90408695]\n",
            " [0.4008206  0.4809546  0.01077517 ... 0.86266816 0.16503544 0.58873546]\n",
            " [0.36267212 0.36395168 0.01794727 ... 0.91692054 0.17945114 0.72879636]], shape=(39998, 40), dtype=float32)\n",
            "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op BiasAdd in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Relu in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Softmax in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "0.5960384153661464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfzr03uyrKRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = z\n",
        "word_vector_length = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_i9e79TsNt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "be321a1e-0c6b-41fd-cd79-9584ff0382f6"
      },
      "source": [
        "input1 = tf.keras.layers.Input(shape=(max_len_multi_prem_,), name='input1')\n",
        "input2 = tf.keras.layers.Input(shape=(max_len_multi_hypo_,), name='input2')\n",
        "embedding1 = tf.keras.layers.Embedding(vocab_size_prem_+1, word_vector_length, input_length=max_len_multi_prem_)(input1)\n",
        "embedding2 = tf.keras.layers.Embedding(vocab_size_hypo_+1, word_vector_length ,input_length=max_len_multi_hypo_)(input2)\n",
        "lstm_shared = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(40,return_sequences = False,kernel_initializer = tf.keras.initializers.lecun_normal(seed=None),unit_forget_bias = True, name = 'lstm_main_1'),name = 'bid_1',merge_mode = 'mul')\n",
        "h1 = lstm_shared(embedding1)\n",
        "h2 = lstm_shared(embedding2)\n",
        "z = tf.math.abs(h1-h2)\n",
        "aux_op = tf.keras.layers.Softmax(name = 'aux_output')(z)\n",
        "d1 = tf.keras.layers.Dense(10, activation='relu')(z)\n",
        "main_op = tf.keras.layers.Dense(4, activation='softmax',name = 'main_output')(d1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Sub in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Mul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TruncatedNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomStandardNormal in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Qr in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op DiagPart in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Sign in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Reshape in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op ConcatV2 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6-xbwoOsNxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "b31f8d14-d182-4888-e706-efad8733192f"
      },
      "source": [
        "model_context = tf.keras.Model(inputs=[input1, input2], outputs=[main_op, aux_op])\n",
        "model_context.compile(optimizer='adam',\n",
        "              loss={'main_output': 'binary_crossentropy', 'aux_output': tf.keras.losses.KLDivergence()},\n",
        "              loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
        "\n",
        "# And trained it via:\n",
        "model_context.fit({'input1':padded_docs_prem_[0:35000,:], 'input2': padded_docs_hypo_[0:35000,:]},\n",
        "          {'main_output': lab[0:35000,:], 'aux_output' : np.asarray(tf.keras.activations.softmax(context[0:35000,:],axis = 1),dtype = np.float32)},\n",
        "          epochs=2, batch_size=32)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Train on 35000 samples\n",
            "Epoch 1/2\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f57c8466048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f57c8466048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Executing op __inference_initialize_variables_68039 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_distributed_function_73994 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "35000/35000 [==============================] - 565s 16ms/sample - loss: 0.4645 - main_output_loss: 0.4583 - aux_output_loss: 0.0312\n",
            "Epoch 2/2\n",
            "35000/35000 [==============================] - 555s 16ms/sample - loss: 0.4023 - main_output_loss: 0.3955 - aux_output_loss: 0.0338\n",
            "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57c865cda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZcb4kPtsN7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1a4f4cc0-ba53-49e3-e2c4-ad68af1e964b"
      },
      "source": [
        "#prediction using progressive net\n",
        "pred = model_context.predict([padded_docs_prem_[35000:,:],padded_docs_hypo_[35000:,:]])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op __inference_distributed_function_83945 in device /job:localhost/replica:0/task:0/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjjPvTGOsN95",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b26f2575-860a-4b09-81a0-b3e78a3e3d24"
      },
      "source": [
        "accuracy_score(np.argmax(pred[0],axis = 1),np.argmax(lab[35000:,:],axis = 1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5712284913965586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unMqEulcsOBJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "31952a84-c77c-441f-8dde-4d160d57fb78"
      },
      "source": [
        "model1 = MyModel1(30,max_len_multi_prem_,max_len_multi_hypo_,vocab_size_prem_,vocab_size_hypo_)\n",
        "model1.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "model1.fit([padded_docs_prem_[0:35000,:],padded_docs_hypo_[0:35000,:]],[np.asarray(lab[0:35000,:],dtype=np.int32)],epochs = 2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method MyModel1.call of <__main__.MyModel1 object at 0x7f56c29cf828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method MyModel1.call of <__main__.MyModel1 object at 0x7f56c29cf828>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "(?, 95, 30)\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op MapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op FlatMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op TensorDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Train on 35000 samples\n",
            "Epoch 1/2\n",
            "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "(?, 95, 30)\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f56bc6e5488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f56bc6e5488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "Executing op __inference_initialize_variables_91746 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "(?, 95, 30)\n",
            "Executing op DestroyResourceOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op __inference_distributed_function_97529 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "35000/35000 [==============================] - 563s 16ms/sample - loss: 1.0567 - acc: 0.4502\n",
            "Epoch 2/2\n",
            "35000/35000 [==============================] - 571s 16ms/sample - loss: 0.9406 - acc: 0.5656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f56c29f2208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbwtgMejsNrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c1001edd-ca08-4b7a-d6d1-44e85f3053c8"
      },
      "source": [
        "x = model1.lstm_shared(model1.embedding1(padded_docs_prem_))\n",
        "y = model1.lstm_shared(model1.embedding2(padded_docs_hypo_))\n",
        "z = tf.math.abs(x-y)\n",
        "print(z)\n",
        "#print(np.sum(z_,axis = 1))\n",
        "#print(np.sum(tf.keras.activations.softmax(z_),axis = 1))\n",
        "z_ = model1.d1(z)\n",
        "fin = model1.d2(z_)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(np.argmax(fin[35000:,:],axis = 1),np.argmax(lab[35000:,:],axis = 1)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing op ResourceGather in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Identity in device /job:localhost/replica:0/task:0/device:CPU:0\n",
            "Executing op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Unpack in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "Executing op Pack in device /job:localhost/replica:0/task:0/device:GPU:0\n",
            "tf.Tensor(\n",
            "[[0.35192475 0.20617585 0.04888998 ... 0.8513858  1.4643469  0.08430769]\n",
            " [0.04488426 0.26570666 0.33149734 ... 0.55467683 1.4643538  0.08430769]\n",
            " [0.58657074 0.5699995  0.8748139  ... 0.8955618  1.4517334  0.08430769]\n",
            " ...\n",
            " [0.4854421  0.35768098 0.55506766 ... 0.01938966 1.468472   0.08650975]\n",
            " [0.8072926  0.4685302  0.39187786 ... 0.34041148 1.4684724  0.08650975]\n",
            " [0.7302002  0.54045737 0.52030456 ... 0.20773755 1.4682944  0.0690666 ]], shape=(39998, 40), dtype=float32)\n",
            "0.5680272108843537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwjIZnSx-8_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}