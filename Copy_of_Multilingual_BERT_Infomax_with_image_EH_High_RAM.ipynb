{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Multilingual BERT Infomax with image EH High RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPy5uglhqQYQ",
        "colab_type": "text"
      },
      "source": [
        "*   **Use iitp.baban Google Drive**\n",
        "*   **SEED = 42** \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1eNCKuMqV_S",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyZMo5A8t2GK",
        "colab_type": "code",
        "outputId": "9d147c29-266b-435c-cfb8-d1210275e3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install bert-tensorflow\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "\n",
        "from bert import optimization\n",
        "from bert import tokenization\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3hC_qnvt5SJ",
        "colab_type": "code",
        "outputId": "060308be-1aad-4196-ee47-6233190dc040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6H9hFfCohXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSZKm3PjqfKw",
        "colab_type": "text"
      },
      "source": [
        "# BERT Pretrained Model Download "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQsRqD2Ht7JY",
        "colab_type": "code",
        "outputId": "8a4c2ddd-7e85-41dc-827c-11df68c1144b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "!unzip multi_cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 11:47:42--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.12.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.12.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M   134MB/s    in 4.9s    \n",
            "\n",
            "2020-06-04 11:47:48 (129 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
            "   creating: multi_cased_L-12_H-768_A-12/\n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuKw9eWfrpv2",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Loading (Text)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs-LArkft9Ha",
        "colab_type": "code",
        "outputId": "305a82f5-0428-4225-91ce-c24b3bf71b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "file = '/content/gdrive/My Drive/COLING 2020/dataset (Cleaned).csv'\n",
        "df = pd.read_csv(file, sep = '\\t')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>english_premise</th>\n",
              "      <th>english_hypo</th>\n",
              "      <th>premise_hindi</th>\n",
              "      <th>hypo_hindi</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>captionID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35101</td>\n",
              "      <td>A band is having their live show recorded.</td>\n",
              "      <td>People are watching a magic show.</td>\n",
              "      <td>एक बैंड उनके लाइव शो को रिकॉर्ड कर रहा है।</td>\n",
              "      <td>लोग एक मैजिक शो देख रहे हैं।</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4414009112.jpg#4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5102</td>\n",
              "      <td>A man in a green hoodie is trying to do a tric...</td>\n",
              "      <td>a man in green</td>\n",
              "      <td>एक हरी हुडी में एक आदमी एक पार्क में अपने स्के...</td>\n",
              "      <td>एक आदमी हरे रंग में</td>\n",
              "      <td>entailment</td>\n",
              "      <td>406308903.jpg#3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25418</td>\n",
              "      <td>The sun is blazing through the trees onto a gr...</td>\n",
              "      <td>the tent is on the beach.</td>\n",
              "      <td>सूरज जंगल में हरे तंबू पर पेड़ों से टकरा रहा है।</td>\n",
              "      <td>तम्बू समुद्र तट पर है।</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>958326692.jpg#0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3988</td>\n",
              "      <td>The white dog is standing on its hind legs, lo...</td>\n",
              "      <td>A white dog is staring over a ledge at a cat.</td>\n",
              "      <td>सफ़ेद कुत्ता अपने हिंद पैरों पर खड़ा है, एक कग...</td>\n",
              "      <td>एक सफ़ेद कुत्ता एक बिल्ली के ऊपर चढ़े हुए को घ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3649802021.jpg#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6663</td>\n",
              "      <td>A skateboarder at a skate park attempting a ra...</td>\n",
              "      <td>A person on a skateboard does a trick.</td>\n",
              "      <td>स्केट पार्क में एक स्केटबोर्डर जो रेल स्लाइड च...</td>\n",
              "      <td>स्केटबोर्ड पर एक व्यक्ति एक चाल करता है।</td>\n",
              "      <td>neutral</td>\n",
              "      <td>5479743540.jpg#3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...         captionID\n",
              "0  35101  ...  4414009112.jpg#4\n",
              "1   5102  ...   406308903.jpg#3\n",
              "2  25418  ...   958326692.jpg#0\n",
              "3   3988  ...  3649802021.jpg#1\n",
              "4   6663  ...  5479743540.jpg#3\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxdLFOYAolBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "496e874e-9cb4-43e3-fa20-629728d6bb59"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/XNLI/XNLI-1.0.zip\n",
        "!unzip XNLI-1.0.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-04 11:48:03--  https://dl.fbaipublicfiles.com/XNLI/XNLI-1.0.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17865352 (17M) [application/zip]\n",
            "Saving to: ‘XNLI-1.0.zip’\n",
            "\n",
            "XNLI-1.0.zip        100%[===================>]  17.04M  12.7MB/s    in 1.3s    \n",
            "\n",
            "2020-06-04 11:48:05 (12.7 MB/s) - ‘XNLI-1.0.zip’ saved [17865352/17865352]\n",
            "\n",
            "Archive:  XNLI-1.0.zip\n",
            "   creating: XNLI-1.0/\n",
            "  inflating: XNLI-1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/XNLI-1.0/\n",
            "  inflating: __MACOSX/XNLI-1.0/._.DS_Store  \n",
            "  inflating: XNLI-1.0/xnli.dev.tsv   \n",
            "  inflating: __MACOSX/XNLI-1.0/._xnli.dev.tsv  \n",
            "  inflating: XNLI-1.0/xnli.dev.jsonl  \n",
            "  inflating: XNLI-1.0/README.md      \n",
            "  inflating: __MACOSX/XNLI-1.0/._README.md  \n",
            "  inflating: XNLI-1.0/xnli.test.jsonl  \n",
            "  inflating: XNLI-1.0/xnli.test.tsv  \n",
            "  inflating: __MACOSX/XNLI-1.0/._xnli.test.tsv  \n",
            "  inflating: __MACOSX/._XNLI-1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id1H4EarpYaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('XNLI-1.0/xnli.test.tsv',sep = '\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAoYVvT_pxqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a0254c6-e6ec-4d3c-e53a-fabe8bfab5ee"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>language</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>promptID</th>\n",
              "      <th>pairID</th>\n",
              "      <th>genre</th>\n",
              "      <th>label1</th>\n",
              "      <th>label2</th>\n",
              "      <th>label3</th>\n",
              "      <th>label4</th>\n",
              "      <th>label5</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ar</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>لم أتحدث معه مرة أخرى.</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>لم أتحدث معه مرة أخرى .</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ar</td>\n",
              "      <td>entailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>كنت مستاء جدا لدرجة أنني بدأت بالحديث معه مرة ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ar</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>دار بيننا حديث رائع.</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>حسنا ، لم أكن أفكر حتى حول ذلك ، لكن كنت محبطا...</td>\n",
              "      <td>دار بيننا حديث رائع .</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ar</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>neutral</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>لم أكن على علم بأنني لم أكن الشخص الوحيد الذي ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar</td>\n",
              "      <td>entailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>كان لدي إنطباع أنني كنت الشخص الوحيد الذي لديه...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ar</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>حصلنا جميعنا على نفس العدد بالضبط بغض النظر عن...</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>واعتقدت أن ذلك شرف لي ، ولا يزال ، ولايزال ، ك...</td>\n",
              "      <td>حصلنا جميعنا على نفس العدد بالضبط بغض النظر عن...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ar</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>أخبروني ،إيه، أنه سيتم استدعائي من قبل شاب في ...</td>\n",
              "      <td>لم يتم إخباري أبداً بأي شيء عن مقابلة أي شخص.</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>أخبروني ، إيه ، أنه سيتم استدعائي من قبل شاب ف...</td>\n",
              "      <td>لم يتم إخباري أبداً بأي شيء عن مقابلة أي شخص .</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ar</td>\n",
              "      <td>entailment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>أخبروني ،إيه، أنه سيتم استدعائي من قبل شاب في ...</td>\n",
              "      <td>لقد أخبروني بأنهم سيقومون بإرسال شاب لأقابله.</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>أخبروني ، إيه ، أنه سيتم استدعائي من قبل شاب ف...</td>\n",
              "      <td>لقد أخبروني بأنهم سيقومون بإرسال شاب لأقابله .</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ar</td>\n",
              "      <td>neutral</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>أخبروني ،إيه، أنه سيتم استدعائي من قبل شاب في ...</td>\n",
              "      <td>لقد جاء الشاب متأخراً قليلاً.</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "      <td>أخبروني ، إيه ، أنه سيتم استدعائي من قبل شاب ف...</td>\n",
              "      <td>لقد جاء الشاب متأخراً قليلاً .</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ar</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>هناك الكثير تستطيع التحدث عنه  وأنا سوف أتاجاو...</td>\n",
              "      <td>أريد أن أخبرك بكل شيء أعرفه عن ذلك!</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>facetoface</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>entailment</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>هناك الكثير تستطيع التحدث عنه وأنا سوف أتاجاوز...</td>\n",
              "      <td>أريد أن أخبرك بكل شيء أعرفه عن ذلك !</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  language  ...  match\n",
              "0       ar  ...   True\n",
              "1       ar  ...   True\n",
              "2       ar  ...   True\n",
              "3       ar  ...  False\n",
              "4       ar  ...   True\n",
              "5       ar  ...   True\n",
              "6       ar  ...   True\n",
              "7       ar  ...   True\n",
              "8       ar  ...   True\n",
              "9       ar  ...   True\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmt_DkfXqzBv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_en = df[(df['language'] == 'en') ].head(5000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfTzbvvzrihd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_hi = df[(df['language'] == 'hi') ].head(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FStyDhXGrirf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_es = df[(df['language'] == 'es') ].head(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqKitPqAripD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_fr = df[(df['language'] == 'fr') ].head(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JzsFQYRridp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_en_train,df_en_test = train_test_split(df_en, test_size=0.1,random_state = SEED,shuffle = True)\n",
        "df_hi_train,df_hi_test = train_test_split(df_hi, test_size=0.1,random_state = SEED,shuffle = True)\n",
        "df_es_train,df_es_test = train_test_split(df_es, test_size=0.1,random_state = SEED,shuffle = True)\n",
        "df_fr_train,df_fr_test = train_test_split(df_fr, test_size=0.1,random_state = SEED,shuffle = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmW01xx0t-zK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train, test = train_test_split(df, test_size=0.1,random_state = SEED,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65ZPFUj2t-86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_eng_hindi(a,b):\n",
        "  b_ = list(a['gold_label'])\n",
        "  assert b_== list(b['gold_label'])\n",
        "  lab = []\n",
        "  \"\"\"\n",
        "  lab  = []\n",
        "  for i in b_:\n",
        "    lab.append(i-1)\n",
        "  \"\"\"\n",
        "  for i in b_:\n",
        "    if i=='contradiction':\n",
        "        lab.append(0)\n",
        "        \n",
        "    elif i=='neutral':\n",
        "        lab.append(1)\n",
        "    elif i== 'entailment':\n",
        "        lab.append(2)\n",
        "    \n",
        "  sentence_1 = list(a['sentence1'])\n",
        "  sentence_2 = list(b['sentence2'])\n",
        "  raw_data_train = {'sentence1_eng': sentence_1, \n",
        "              'sentence2_hindi': sentence_2,\n",
        "          'label': lab}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['sentence1_eng','sentence2_hindi','label'])\n",
        "  return df\n",
        "\n",
        "def get_data_hindi_eng(a,b):\n",
        "  b_ = list(a['gold_label'])\n",
        "  assert b_== list(b['gold_label'])\n",
        "  lab = []\n",
        "  \"\"\"\n",
        "  lab  = []\n",
        "  for i in b_:\n",
        "    lab.append(i-1)\n",
        "  \"\"\"\n",
        "  for i in b_:\n",
        "    if i=='contradiction':\n",
        "        lab.append(0)\n",
        "        \n",
        "    elif i=='neutral':\n",
        "        lab.append(1)\n",
        "    elif i== 'entailment':\n",
        "        lab.append(2)\n",
        "    \n",
        "  sentence_1 = list(a['sentence1'])\n",
        "  sentence_2 = list(b['sentence2'])\n",
        "  raw_data_train = {'sentence1_hindi': sentence_1, \n",
        "              'sentence2_eng': sentence_2,\n",
        "          'label': lab}\n",
        "  df = pd.DataFrame(raw_data_train, columns = ['sentence1_hindi','sentence2_eng','label'])\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzGehz_Rt_FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_eng_hindi = get_data_eng_hindi(df_en_train,df_hi_train)\n",
        "train_hindi_eng = get_data_hindi_eng(df_es_train,df_fr_train)\n",
        "\n",
        "test_eng_hindi = get_data_eng_hindi(df_en_test,df_hi_test)\n",
        "test_hindi_eng = get_data_hindi_eng(df_es_test,df_fr_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhRL6C9t_RQ",
        "colab_type": "code",
        "outputId": "1dfd5d6f-20d4-451f-e2a3-b229898452a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train_eng_hindi[0:3]\n",
        "\n",
        "print(train_eng_hindi)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                          sentence1_eng  ... label\n",
            "0     You already understand the importance of story...  ...     0\n",
            "1     ..the world's most thoughtful and motivating n...  ...     0\n",
            "2     Um, no, to be honest, I never read any of the ...  ...     1\n",
            "3                      You are making too much of this.  ...     2\n",
            "4     Both of these can be altered without altering ...  ...     0\n",
            "...                                                 ...  ...   ...\n",
            "4495                 Time foresees trouble for the SAT.  ...     1\n",
            "4496  And she said then her mama, her mama leaned fo...  ...     2\n",
            "4497  Both Secretary Powell and Secretary Rumsfeld a...  ...     1\n",
            "4498  Since 1914, Civic has maintained its uniquenes...  ...     2\n",
            "4499  it was was a lot of fun yeah it was um  real p...  ...     2\n",
            "\n",
            "[4500 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekq3kNIbvGGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "6101815b-fdc2-409d-8213-439934470e38"
      },
      "source": [
        "train_hindi_eng[0:3]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1_hindi</th>\n",
              "      <th>sentence2_eng</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ya entiendes la importancia de la narración, p...</td>\n",
              "      <td>Les contes, la poésie, les chansons et le théâ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>...los escritores de naturaleza más considerad...</td>\n",
              "      <td>Personne n'écrit sur la nature.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hum, no, para ser sincero, nunca leí ninguno d...</td>\n",
              "      <td>Je n'ai lu aucun livre de plus de 100 pages.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     sentence1_hindi  ... label\n",
              "0  Ya entiendes la importancia de la narración, p...  ...     0\n",
              "1  ...los escritores de naturaleza más considerad...  ...     0\n",
              "2  Hum, no, para ser sincero, nunca leí ninguno d...  ...     1\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX93ehCUvGoo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "96a122af-be46-415a-fdf6-6fb070b2cef1"
      },
      "source": [
        "test_eng_hindi[0:3]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1_eng</th>\n",
              "      <th>sentence2_hindi</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can a parent identify the difference betwe...</td>\n",
              "      <td>एक माता-पिता सोचता है कि दो साल की उम्र में बा...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>According to a Board official, the Board's sec...</td>\n",
              "      <td>बोर्ड ने एसबीए प्रमाणपत्र नहीं दिए और उन्होंने...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Finally, postal density appears to be a more i...</td>\n",
              "      <td>डाक घनत्व में वितरण लागत पर मात्रा के प्रभाव स...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       sentence1_eng  ... label\n",
              "0  How can a parent identify the difference betwe...  ...     1\n",
              "1  According to a Board official, the Board's sec...  ...     1\n",
              "2  Finally, postal density appears to be a more i...  ...     1\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZU37OctvGui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9d43148c-0316-42f2-bba0-f1b6e4e45f1f"
      },
      "source": [
        "test_hindi_eng[0:3]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1_hindi</th>\n",
              "      <th>sentence2_eng</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>¿Cómo puede un padre reconocer la diferencia e...</td>\n",
              "      <td>Un parent pense qu'être incapable de parler av...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Según un representante de la Junta, la documen...</td>\n",
              "      <td>Le Conseil n'a pas donné les certifications SB...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Finalmente, la densidad postal parece ser un i...</td>\n",
              "      <td>La densité postale a deux fois l'impact du vol...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     sentence1_hindi  ... label\n",
              "0  ¿Cómo puede un padre reconocer la diferencia e...  ...     1\n",
              "1  Según un representante de la Junta, la documen...  ...     1\n",
              "2  Finalmente, la densidad postal parece ser un i...  ...     1\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSgcc6Xrrp6y",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Loading (Image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGtoqnUXuGa7",
        "colab_type": "code",
        "outputId": "33a43bb9-761f-478c-de97-50356747614f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "'''\n",
        "#Flickr30K Dataset Attach and Image Preprocess\n",
        "\n",
        "uploaded = files.upload() #Upload the API Key for Kaggle (Kaggle.json)\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d hsankesara/flickr-image-dataset\n",
        "!unzip \"/content/flickr-image-dataset.zip\"\n",
        "\n",
        "file = '/content/gdrive/My Drive/COLING 2020/dataset.csv'\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# Testing for Proper loading of Image\n",
        "test_caption = list(df['captionID'])[10][:-2]\n",
        "image_file = \"/content/flickr30k_images/flickr30k_images/\"\n",
        "img = Image.open(image_file + test_caption)\n",
        "plt.imshow(img)\n",
        "\n",
        "img_lib = \"/content/flickr30k_images/flickr30k_images/\"\n",
        "images = list(df['captionID'])\n",
        "for i in range(len(images)):\n",
        "  images[i] = images[i][:-2]   #Last 2 characters contains non relevant hash-values\n",
        "\n",
        "image_height,image_width = 100,100  #Optimal for RAM Usage\n",
        "\n",
        "image_array = np.zeros((36072,image_height,image_width,3), dtype = np.float32)  #Because 146 error entries\n",
        "index = 0\n",
        "errors = []\n",
        "for i in images:\n",
        "  try:\n",
        "    print(\"Processing File: \"+i)\n",
        "    img = Image.open(img_lib + i)\n",
        "    img = img.resize((image_height,image_width))\n",
        "    img = np.asarray(img, dtype = np.float32)\n",
        "    image_array[index] = img\n",
        "    index += 1\n",
        "  except:\n",
        "    index += 1\n",
        "    print(\"Error at Index: \"+ str(index))\n",
        "    errors.append(index)\n",
        "\n",
        "np.array(errors).dump(open('Image Error Indices.npy', 'wb'))    #Useful for Sentence Deletion or Manual Image Insertion\n",
        "images_array = train_images_array/255\n",
        "train_imgages, test_images = train_test_split(images_array, test_size=0.1,random_state = SEED, shuffle = True)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# Image Numpy File loading Already Resized and Preprocessed\n",
        "file = '/content/gdrive/My Drive/COLING 2020/img_array.npy'\n",
        "images_array = np.load(file)\n",
        "\n",
        "# Train Test Split for Input in SOTA \n",
        "train_images, test_images = train_test_split(images_array, test_size=0.1,random_state = SEED, shuffle = True)\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32333, 100, 100, 3)\n",
            "(3593, 100, 100, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck6IUQLWrqBZ",
        "colab_type": "text"
      },
      "source": [
        "# Using SOTA Image DNNs for extracting pretrained features\n",
        "\n",
        "*   VGG19\n",
        "*   NASNet Large\n",
        "*   InceptionResnetV2 [InceptionResnetV2 Paper](https://arxiv.org/abs/1602.07261)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pQfg1EguMFD",
        "colab_type": "code",
        "outputId": "272fd110-7dbb-44d2-e5d6-114e2ba9698a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Planning to use NasNetLarge\n",
        "from tensorflow.keras import applications\n",
        "\n",
        "#Image_Model = applications.NASNetLarge(include_top = False, input_shape = (100, 100, 3), weights = \"imagenet\") \n",
        "#Image_Model = applications.VGG19(include_top = False, input_shape = (100, 100, 3), weights = \"imagenet\")\n",
        "Image_Model = applications.InceptionResNetV2(include_top = False, input_shape = (100, 100, 3), weights = \"imagenet\")\n",
        "x = Image_Model.output\n",
        "img_features = tf.keras.layers.Flatten()(x)\n",
        "Image_model_final = tf.keras.Model(Image_Model.input, img_features)\n",
        "\n",
        "train_img_features = Image_model_final.predict(train_images)\n",
        "test_img_features = Image_model_final.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmRBelV2rqE6",
        "colab_type": "text"
      },
      "source": [
        "# Changing Raw Inpput to Bert Readable Inputs (Train and Test) Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFaxQ5KuO3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = [0,1,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQZElAGAuS-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples_eng = train_eng_hindi.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['sentence1_eng'], \n",
        "                                                                   text_b = x['sentence2_hindi'], \n",
        "                                                                   label = x['label']), axis = 1)\n",
        "train_InputExamples_hindi = train_hindi_eng.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['sentence1_hindi'], \n",
        "                                                                   text_b = x['sentence2_eng'], \n",
        "                                                                   label = x['label']), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95ixiiZuuTEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_InputExamples_eng = test_eng_hindi.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['sentence1_eng'], \n",
        "                                                                   text_b = x['sentence2_hindi'], \n",
        "                                                                   label = x['label']), axis = 1)\n",
        "test_InputExamples_hindi = test_hindi_eng.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x['sentence1_hindi'], \n",
        "                                                                   text_b = x['sentence2_eng'], \n",
        "                                                                   label = x['label']), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMUbG7jwuTKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = \"multi_cased_L-12_H-768_A-12/vocab.txt\"\n",
        "def create_tokenizer_from_hub_module():\n",
        " \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=True)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vZZPEg7rqJ7",
        "colab_type": "text"
      },
      "source": [
        "# Checking BERT Hindi and English Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaOnSXIIuZBM",
        "colab_type": "code",
        "outputId": "d0b69776-67d6-4be7-88fa-d066a079828a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(tokenizer.tokenize(\"how are you\"))\n",
        "print(tokenizer.tokenize(\"एक आदमी गोरा सिर वाली महिला से बात कर रहा है।\"))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'are', 'you']\n",
            "['एक', 'आ', '##द', '##मी', 'ग', '##ोर', '##ा', 'स', '##िर', 'वाली', 'महिला', 'स', 'बात', 'कर', 'रहा', 'ह', '।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vsA-bBYrqUY",
        "colab_type": "text"
      },
      "source": [
        "# Changing Raw Inpput to Bert Readable Inputs (Train and Test) Function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH764RQWubgy",
        "colab_type": "code",
        "outputId": "114ef71d-4c52-4701-a1fc-5b28d2f06f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features_eng = bert.run_classifier.convert_examples_to_features(train_InputExamples_eng, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "train_features_hindi = bert.run_classifier.convert_examples_to_features(train_InputExamples_hindi, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4500\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] you already understand the importance of story ##telling , poetry , song , and theatre in fost ##ering empat ##hy , com ##pass ##ion , and the ima ##gination . [SEP] कथा ##वा ##चन , कविता , गीत , और र ##गम ##च म ##हत ##व ##ही ##न ह और स ##हान ##भ ##ति , कर ##णा और क ##ल ##पन ##ा को ब ##ढ ##ावा द ##न म ब ##िल ##क ##ल ब ##कार ह । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13028 19034 49151 10105 21912 10108 13617 48027 117 32116 117 12011 117 10111 28016 10106 11265 19232 30593 19275 117 10212 36388 11046 117 10111 10105 13872 69428 119 102 84535 28960 91405 117 91639 117 93095 117 10977 891 103067 16940 889 108775 15070 24667 11453 899 10977 898 67117 60270 24877 117 16192 69965 10977 865 11714 68053 11208 11267 887 111204 81027 882 11453 889 887 27391 12151 11714 887 25561 899 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] . . the world ' s most thought ##ful and motiv ##ating nature writers . [SEP] कोई भी क ##दर ##त क बार म न ##ही ल ##ि ##ख ##ता ह । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 119 119 10105 11356 112 187 10992 18957 14446 10111 63598 33121 16613 35729 119 102 38207 13286 865 71478 11845 865 44551 889 884 24667 893 12878 27841 13537 899 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] um , no , to be hon ##est , i never read any of the books i was supposed to . [SEP] म ##न 100 स अधिक प ##ष ##ठ ##ो की कि ##ता ##ब न ##ही प ##ढ ##ी ह । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 10293 117 10192 117 10114 10347 14923 13051 117 177 14794 24944 11178 10108 10105 15174 177 10134 59516 10114 119 102 889 11453 10407 898 23586 885 39765 35247 13718 10826 14117 13537 18351 884 24667 885 111204 10914 899 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] you are making too much of this . [SEP] त ##म क ##छ बना र ##ह हो । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 13028 10301 14293 16683 13172 10108 10531 119 102 880 13841 865 108021 60701 891 17110 13220 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 2 (id = 2)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] both of these can be altered without alter ##ing the antico ##don - co ##don match ##ing mechanism . [SEP] ए ##टी ##को ##ड ##न - कोड ##न म ##िला ##न त ##तर को ब ##दल बिना इन ##म स किसी को ब ##दल ##ा न ##ही जा सकता । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11408 10108 11762 10944 10347 78598 13663 42141 10230 10105 36232 15081 118 11170 15081 12356 10230 50706 119 102 860 58580 12512 20691 11453 118 59850 11453 889 33156 11453 880 47224 11267 887 99989 98770 30114 13841 898 27692 11267 887 99989 11208 884 24667 24562 26886 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:Writing example 0 of 4500\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] ya ent ##iende ##s la importancia de la narra ##cion , poesia , can ##cion y teatro a la hora de f ##omen ##tar la empat ##ia , com ##pasi ##on e ima ##gina ##cion . [SEP] les contes , la po ##esie , les chansons et le theatre sont ins ##ign ##ifiant ##s et sont ab ##sol ##ument in ##uti ##les pour pro ##mou ##voir l ' empat ##hie , la com ##pass ##ion et l ' ima ##gination . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 10549 61047 74684 10107 10109 27587 10104 10109 63335 15204 117 37966 117 10944 15204 193 17796 169 10109 24301 10104 174 37778 12819 10109 30593 10280 117 10212 104565 10263 173 13872 24769 15204 119 102 10152 92621 117 10109 10514 86258 117 10152 34866 10131 10141 28016 10647 15498 58445 98742 10107 10131 10647 11357 43115 58079 10106 19065 11268 10322 11284 36038 34341 180 112 30593 72287 117 10109 10212 36388 11046 10131 180 112 13872 69428 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] . . . los escritores de naturaleza mas considerados y motiv ##adores del mundo . [SEP] personne n ' e ##crit sur la nature . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 119 119 119 10182 57473 10104 39839 11856 63586 193 63598 29837 10127 13137 119 102 29275 182 112 173 87349 10326 10109 16613 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] hu ##m , no , para ser since ##ro , nunca lei ning ##uno de los libros que se su ##pon ##ia tenia que leer . [SEP] je n ' ai lu aucun livre de plus de 100 pages . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 26506 10147 117 10192 117 10220 10493 11764 10567 117 19096 15339 12411 25091 10104 10182 29450 10121 10126 10198 27119 10280 16217 10121 58667 119 102 10144 182 112 11346 14657 30366 18807 10104 10563 10104 10407 20255 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] estas haciendo una montana de un gran ##o de arena . [SEP] vous cree ##z quelque chose . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 17958 44037 10153 82317 10104 10119 11432 10133 10104 33080 119 102 24931 54910 10305 40031 25720 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 2 (id = 2)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] ambos pueden alter ##arse sin alter ##ar el mecanismo de coincide ##ncia del co ##don antico ##don . [SEP] aucun de ceux - ci ne peuvent etre alter ##es sans alter ##er le me ##cani ##sme d ' association antico ##don - co ##don . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 18860 15166 42141 28790 10795 42141 10354 10125 72838 10104 81860 13212 10127 11170 15081 36232 15081 119 102 30366 10104 20859 118 11322 10554 18715 43789 42141 10171 13115 42141 10165 10141 10911 108944 17228 172 112 18061 36232 15081 118 11170 15081 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MudlwF6udaj",
        "colab_type": "code",
        "outputId": "17a052fd-b0d6-4b5b-aa58-6854d29eccdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "test_features_eng = bert.run_classifier.convert_examples_to_features(test_InputExamples_eng, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features_hindi = bert.run_classifier.convert_examples_to_features(test_InputExamples_hindi, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 500\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] how can a parent identify the difference between a language disorder and normal language development ? [SEP] एक मा ##ता - पिता स ##ो ##च ##ता ह कि दो साल की उ ##म ##र म बात कर ##न म अ ##सम ##र ##थ होना असा ##मान ##य ह । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 14796 10944 169 43045 51361 10105 30856 10948 169 13702 55405 10111 16626 13702 13405 136 102 11186 32629 13537 118 69650 898 13718 16940 13537 899 14117 29784 53749 10826 855 13841 11549 889 70811 16192 11453 889 851 105794 11549 30534 103673 107666 32742 13874 899 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] according to a board official , the board ' s section 605 ( b ) certifications were not provided separately to the small business administration ( s ##ba ) chief co ##unsel for ad ##vocacy . [SEP] ब ##ोर ##ड न एस ##बी ##ए पर ##मा ##ण ##प ##तर न ##ही दिए और उन ##ह ##ोन इस न ##िर ##धार ##ित कर ##न ##वाल का ##र ##या ##लय पर छ ##ोड दिया । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 18071 10114 169 17936 14731 117 10105 17936 112 187 14893 48141 113 170 114 92587 10309 10472 16491 91614 10114 10105 12474 14155 17941 113 187 10537 114 19421 11170 78067 10142 10840 110510 119 102 887 41937 20691 884 55046 40153 22599 12213 12347 14512 18187 47224 884 24667 103821 10977 68993 17110 73354 14265 884 46354 88704 13184 16192 11453 94597 11081 11549 15168 89505 12213 871 69334 20226 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] finally , postal density appears to be a more important driver of unit street delivery costs than volume over the actual ranges in franc ##e and the u . s . [SEP] ड ##ा ##क घ ##न ##त ##व म वि ##तर ##ण ला ##गत पर मा ##तर ##ा क पर ##भा ##व स दो ##ग ##ना पर ##भा ##व प ##ड ##ता ह . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 21256 117 30715 23370 20296 10114 10347 169 10798 12452 25926 10108 16511 23840 55626 34495 11084 15901 10491 10105 14012 74397 10106 63184 10112 10111 10105 189 119 187 119 102 877 11208 12151 868 11453 11845 15070 889 55190 47224 14512 21147 49824 12213 32629 47224 11208 865 12213 104741 15070 898 29784 19741 16380 12213 104741 15070 885 20691 13537 899 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] any higher form of thinking , he pointed out , rs ##t appears in social communication , between the child and representatives of his or her culture as they engage in a joint activity . [SEP] स ##ाम ##ान ##य ग ##ति ##वि ##धि ##य ##ो को स ##ा ##झा करना कभी - क ##भा ##र स ##ो ##च क उ ##च ##च स ##वर ##प ##ो को स ##ा ##झा कर ##न म स ##हा ##यक होता ह । [SEP]\n",
            "INFO:tensorflow:input_ids: 101 11178 17981 12188 10108 56294 117 10261 62288 10950 117 48495 10123 20296 10106 12142 24990 117 10948 10105 18048 10111 49959 10108 10226 10345 10485 15162 10146 10689 38391 10106 169 25680 22205 119 102 898 49362 21202 13874 867 24877 72233 32831 13874 13718 11267 898 11208 93224 36647 50058 118 865 104741 11549 898 13718 16940 865 855 16940 16940 898 22568 18187 13718 11267 898 11208 93224 16192 11453 889 898 56523 51094 16654 899 920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 2 (id = 2)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] and it still s ##care ##d me [SEP] म थ ##ोड ##ा घ ##बर ##ाया ह ##आ था | [SEP]\n",
            "INFO:tensorflow:input_ids: 101 10111 10271 12647 187 22277 10162 10911 102 889 881 69334 11208 868 41082 67341 899 111193 13794 196 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:Writing example 0 of 500\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] ¿ como puede un padre re ##conoce ##r la diferencia entre un tras ##torno linguistic ##o y un desarrollo de lenguaje normal ? [SEP] un parent pense qu ' etre in ##cap ##able de parler avant l ' age de deux ans est ano ##rmal . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 224 10225 12994 10119 13703 11639 91670 10129 10109 28204 10402 10119 14807 100921 105768 10133 193 10119 21154 10104 65621 16626 136 102 10119 43045 77184 10608 112 43789 10106 93103 13096 10104 59645 12851 180 112 12089 10104 11051 11744 10176 12797 66619 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] segun un representante de la junta , la document ##aci ##on de la seccion 605 ( b ) de la junta no se entre ##go por separado al abogado principal de la defensa de la small business administration ( s ##ba ) . [SEP] le conseil n ' a pas donne les certifications s ##ba , et ont laisse cela au bureau de l ' ass ##esse ##ur . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 60169 10119 45938 10104 10109 67656 117 10109 25166 28841 10263 10104 10109 41143 48141 113 170 114 10104 10109 67656 10192 10126 10402 10797 10183 92962 10164 69889 11652 10104 10109 24081 10104 10109 12474 14155 17941 113 187 10537 114 119 102 10141 24898 182 112 169 10801 17717 10152 92587 187 10537 117 10131 11378 54613 24552 10257 32340 10104 180 112 13935 24641 10546 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] finalmente , la densidad postal parece ser un impulso ##r mas importante de los costo ##s unit ##arios de entrega en la calle que el volumen sobre los rango ##s reales en francia y los estados uni ##dos . [SEP] la dens ##ite postal ##e a deux fois l ' impact du volume sur les co ##uts de liv ##rais ##on . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 18349 117 10109 17062 30715 30395 10493 10119 82896 10129 11856 12596 10104 10182 57513 10107 16511 45356 10104 47937 10110 10109 27823 10121 10125 56889 10690 10182 39715 10107 58339 10110 29647 193 10182 30493 69191 11181 119 102 10109 37144 12704 30715 10112 169 11051 13224 180 112 21316 10168 15901 10326 10152 11170 33876 10104 25585 35885 10263 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] cualquier forma superior de pensamiento , sen ##alo , aparece primero en la comunica ##cion social entre el nin ##o y los representantes de su cultura cuando participa ##n en una actividad conjunt ##a . [SEP] partage ##r des act ##ivi ##tes communes est parfois utile pour partage ##r de plus hautes formes de raison ##nement . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 20232 11041 15855 10104 84918 117 12954 22219 117 20962 23446 10110 10109 93268 15204 12142 10402 10125 13587 10133 193 10182 49896 10104 10198 15501 12368 38155 10115 10110 10153 29871 39892 10113 119 102 67310 10129 10139 19833 22317 11197 13831 10176 22420 62651 10322 67310 10129 10104 10563 73442 25049 10104 21144 32910 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 2 (id = 2)\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: None\n",
            "INFO:tensorflow:tokens: [CLS] y toda ##via me asus ##to [SEP] j ' av ##ais juste un peu peur . [SEP]\n",
            "INFO:tensorflow:input_ids: 101 193 15650 13372 10911 61734 10340 102 178 112 10170 12985 45605 10119 14574 90908 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzqiIMgJrq-w",
        "colab_type": "text"
      },
      "source": [
        "# CLTE-BERT Custom Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVk6Z7w4uo8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use model.get_sequence_output()\n",
        "  # instead.\n",
        "  output_layer = model.get_pooled_output()\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels,output_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels,hidden_context) = create_model(\n",
        "        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    \"\"\"\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "    \"\"\"\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "       \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      \n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities,\"labels\": predicted_labels, \"hidden_context\": hidden_context})\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBkIEe6Hrq79",
        "colab_type": "text"
      },
      "source": [
        "# CLTE-BERT Custom Model Definition with **Image Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PibwhKRPupyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_img(img_features,bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use model.get_sequence_output()\n",
        "  # instead.\n",
        "  output_layer = model.get_pooled_output()\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  old_size = img_features.shape[-1].value\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "  \n",
        "  output_weights_img = tf.get_variable(\n",
        "      \"output_weights_img\", [hidden_size,old_size], \n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias_img = tf.get_variable(\n",
        "      \"output_bias_img\", [hidden_size], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    img_features = tf.matmul(img_features, output_weights_img, transpose_b=True)\n",
        "    img_features = tf.nn.bias_add(img_features, output_bias_img)\n",
        "    img_features = tf.nn.relu(img_features)\n",
        "    output_layer = tf.math.multiply(output_layer,img_features)\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels,output_layer)\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_builder_img(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    img_features = features[\"img_features\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels,hidden_context) = create_model_img(\n",
        "        img_features, bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    \"\"\"\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "    \"\"\"\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "       \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      \n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities,\"labels\": predicted_labels, \"hidden_context\": hidden_context})\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxarj7wkrq5j",
        "colab_type": "text"
      },
      "source": [
        "# CLTE-Progressive-BERT Custom Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESrCwHX2usTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_progressive(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings,hidden_context):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use model.get_sequence_output()\n",
        "  # instead.\n",
        "  output_layer = model.get_pooled_output()\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "\n",
        "    output_layer_probs = tf.nn.softmax(output_layer,axis = -1)\n",
        "    #loss = y_true * log(y_true / y_pred)\n",
        "    hidden_context = tf.nn.softmax(hidden_context,axis = -1)\n",
        "    per_example_kd_loss = tf.keras.losses.KLD(hidden_context,output_layer_probs)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "\n",
        "    kd_loss_weight = 0.2 #hyperparameter\n",
        "    per_example_kd_loss = kd_loss_weight*per_example_kd_loss\n",
        "\n",
        "    per_example_loss += per_example_kd_loss\n",
        "\n",
        "    \n",
        "\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_builder_progressive(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    hidden_context = features[\"hidden_context\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels) = create_model_progressive(\n",
        "        bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings,hidden_context)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    \"\"\"\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    \"\"\"\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      \n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities,\"labels\": predicted_labels})\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya64btz5rq2y",
        "colab_type": "text"
      },
      "source": [
        "# CLTE-Progressive-BERT Custom Model Definition with **Image Input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZThLldNPuu88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_progressive_img(img_features,bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 labels, num_labels, use_one_hot_embeddings,hidden_context):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "  model = bert.run_classifier.modeling.BertModel(\n",
        "      config=bert_config,\n",
        "      is_training=is_training,\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      token_type_ids=segment_ids,\n",
        "      use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "  # In the demo, we are doing a simple classification task on the entire\n",
        "  # segment.\n",
        "  #\n",
        "  # If you want to use the token-level output, use model.get_sequence_output()\n",
        "  # instead.\n",
        "  output_layer = model.get_pooled_output()\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  old_size = img_features.shape[-1].value\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "  \n",
        "  output_weights_img = tf.get_variable(\n",
        "      \"output_weights_img\", [hidden_size,old_size], \n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias_img = tf.get_variable(\n",
        "      \"output_bias_img\", [hidden_size], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    if is_training:\n",
        "      # I.e., 0.1 dropout\n",
        "      output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    img_features = tf.matmul(img_features, output_weights_img, transpose_b=True)\n",
        "    img_features = tf.nn.bias_add(img_features, output_bias_img)\n",
        "    img_features = tf.nn.relu(img_features)\n",
        "    print('shape of img features {}'.format(np.shape(img_features)))\n",
        "    output_layer  = tf.math.multiply(img_features,output_layer)\n",
        "    output_layer_probs = tf.nn.softmax(output_layer,axis = -1)\n",
        "    #loss = y_true * log(y_true / y_pred)\n",
        "    hidden_context = tf.nn.softmax(hidden_context,axis = -1)\n",
        "    per_example_kd_loss = tf.keras.losses.KLD(hidden_context,output_layer_probs)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    probabilities = tf.nn.softmax(logits, axis=-1)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "\n",
        "    kd_loss_weight = 0.2 #hyperparameter\n",
        "    per_example_kd_loss = kd_loss_weight*per_example_kd_loss\n",
        "\n",
        "    per_example_loss += per_example_kd_loss\n",
        "\n",
        "    \n",
        "\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "\n",
        "    return (loss, per_example_loss, logits, probabilities,predicted_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def model_fn_builder_img_progressive(bert_config, num_labels, init_checkpoint, learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    tf.logging.info(\"*** Features ***\")\n",
        "    for name in sorted(features.keys()):\n",
        "      tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    hidden_context = features[\"hidden_context\"]\n",
        "    img_features = features[\"img_features\"]\n",
        "    is_real_example = None\n",
        "    if \"is_real_example\" in features:\n",
        "      is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "    else:\n",
        "      is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "    (total_loss, per_example_loss, logits, probabilities,predicted_labels) = create_model_progressive_img(\n",
        "        img_features,bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n",
        "        num_labels, use_one_hot_embeddings,hidden_context)\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    initialized_variable_names = {}\n",
        "    scaffold_fn = None\n",
        "    if init_checkpoint:\n",
        "      (assignment_map, initialized_variable_names\n",
        "      ) = bert.run_classifier.modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "      if use_tpu:\n",
        "\n",
        "        def tpu_scaffold():\n",
        "          tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "          return tf.train.Scaffold()\n",
        "\n",
        "        scaffold_fn = tpu_scaffold\n",
        "      else:\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "    \"\"\"\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "    \"\"\"\n",
        "    output_spec = None\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "      train_op = optimization.create_optimizer(\n",
        "          total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          train_op=train_op)\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "\n",
        "      def metric_fn(per_example_loss, label_ids, logits, is_real_example):\n",
        "        predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
        "        accuracy = tf.metrics.accuracy(\n",
        "            labels=label_ids, predictions=predictions, weights=is_real_example)\n",
        "        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"eval_loss\": loss,\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(per_example_loss, label_ids, logits, is_real_example)\n",
        "      \n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          loss=total_loss,\n",
        "          eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      output_spec = tf.estimator.EstimatorSpec(\n",
        "          mode=mode,\n",
        "          predictions={\"probabilities\": probabilities,\"labels\": predicted_labels})\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uNc6dcsrqia",
        "colab_type": "text"
      },
      "source": [
        "# Input Functions\n",
        "\n",
        "1.   CLTE-BERT\n",
        "2.   CLTE-BERT with Image\n",
        "3.   CLTE-BERT-Progressive with Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n8-XpQ5uxFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn_builder(features, hidden_context,seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "    hidden_shape = hidden_context.shape[-1]\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "\n",
        "        \"hidden_context\":\n",
        "            tf.constant(hidden_context, shape = [num_examples,hidden_shape], dtype = tf.float32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "\n",
        "def input_fn_builder_img(img_features,features,seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "    hidden_shape_img = img_features.shape[-1]\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "\n",
        "        \"img_features\":\n",
        "            tf.constant(img_features, shape = [num_examples,hidden_shape_img], dtype = tf.float32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "\n",
        "\n",
        "def input_fn_builder_pr_img(img_features,features,hidden_context,seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "    hidden_shape_img = img_features.shape[-1]\n",
        "    hidden_shape = hidden_context.shape[-1]\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "\n",
        "        \"img_features\":\n",
        "            tf.constant(img_features, shape = [num_examples,hidden_shape_img], dtype = tf.float32),\n",
        "\n",
        "        \"hidden_context\":\n",
        "            tf.constant(hidden_context, shape = [num_examples,hidden_shape], dtype = tf.float32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJqVRXAurqgj",
        "colab_type": "text"
      },
      "source": [
        "# Trainer Functions for BERT (With and Without Image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trvxhdrguz2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epochs = 2 # Number of Training Epochs \n",
        "\n",
        "\n",
        "def train(output_dir,input_fn,input_fn_builder_progressive = False,hidden_context = None):\n",
        "  CONFIG_FILE = \"multi_cased_L-12_H-768_A-12/bert_config.json\"\n",
        "  INIT_CHECKPOINT = \"multi_cased_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "\n",
        "  BATCH_SIZE = 28\n",
        "  LEARNING_RATE = 2e-5\n",
        "  NUM_TRAIN_EPOCHS = Epochs\n",
        "  # Warmup is a period of time where hte learning rate \n",
        "  # is small and gradually increases--usually helps training.\n",
        "  WARMUP_PROPORTION = 0.1\n",
        "  # Model configs\n",
        "  SAVE_CHECKPOINTS_STEPS = 15000\n",
        "  SAVE_SUMMARY_STEPS = 100\n",
        "  OUTPUT_DIR = output_dir\n",
        "  # Compute # train and warmup steps from batch size\n",
        "  num_train_steps = int(len(input_fn) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "  print(num_train_steps)\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      model_dir=OUTPUT_DIR,\n",
        "      save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "  # Specify outpit directory and number of checkpoint steps to save\n",
        "  if input_fn_builder_progressive==False:\n",
        "  \n",
        "\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "      bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "      num_labels=4, #number of unique labels\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=False,\n",
        "      use_one_hot_embeddings=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "  \n",
        "  \n",
        "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "        features=input_fn,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "    \n",
        "\n",
        "  else:\n",
        "\n",
        "    model_fn_pr = model_fn_builder_progressive(\n",
        "      bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "      num_labels=4, #number of unique labels\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=False,\n",
        "      use_one_hot_embeddings=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn_pr,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "  \n",
        "    train_input_fn = input_fn_builder(\n",
        "        features=input_fn,\n",
        "        hidden_context=hidden_context,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "  print(f'Beginning Training!')\n",
        "  %timeit\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  return estimator\n",
        "\n",
        "\n",
        "def train_img(img_features,output_dir,input_fn,input_fn_builder_progressive = False,hidden_context = None):\n",
        "  CONFIG_FILE = \"multi_cased_L-12_H-768_A-12/bert_config.json\"\n",
        "  INIT_CHECKPOINT = \"multi_cased_L-12_H-768_A-12/bert_model.ckpt\"\n",
        "\n",
        "  BATCH_SIZE = 28\n",
        "  LEARNING_RATE = 2e-5\n",
        "  NUM_TRAIN_EPOCHS = Epochs              \n",
        "  # Warmup is a period of time where hte learning rate \n",
        "  # is small and gradually increases--usually helps training.\n",
        "  WARMUP_PROPORTION = 0.1\n",
        "  # Model configs\n",
        "  SAVE_CHECKPOINTS_STEPS = 15000\n",
        "  SAVE_SUMMARY_STEPS = 100\n",
        "  OUTPUT_DIR = output_dir\n",
        "  # Compute # train and warmup steps from batch size\n",
        "  num_train_steps = int(len(input_fn) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "  num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "  print(num_train_steps)\n",
        "  run_config = tf.estimator.RunConfig(\n",
        "      model_dir=OUTPUT_DIR,\n",
        "      save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "      save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "  # Specify outpit directory and number of checkpoint steps to save\n",
        "  if input_fn_builder_progressive==False:\n",
        "  \n",
        "\n",
        "\n",
        "    model_fn = model_fn_builder_img(\n",
        "      bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "      num_labels=4, #number of unique labels\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=False,\n",
        "      use_one_hot_embeddings=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "  \n",
        "  \n",
        "    train_input_fn = input_fn_builder_img(\n",
        "        img_features = img_features,\n",
        "        features=input_fn,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "    \n",
        "\n",
        "  else:\n",
        "\n",
        "    model_fn_pr = model_fn_builder_img_progressive(\n",
        "      bert_config=bert.run_classifier.modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "      num_labels=4, #number of unique labels\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      use_tpu=False,\n",
        "      use_one_hot_embeddings=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    estimator = tf.estimator.Estimator(\n",
        "      model_fn=model_fn_pr,\n",
        "      config=run_config,\n",
        "      params={\"batch_size\": BATCH_SIZE})\n",
        "\n",
        "  \n",
        "    train_input_fn = input_fn_builder_pr_img(\n",
        "        img_features = img_features,\n",
        "        features=input_fn,\n",
        "        hidden_context=hidden_context,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=True,\n",
        "        drop_remainder=False)\n",
        "\n",
        "  print(f'Beginning Training!')\n",
        "  %timeit\n",
        "\n",
        "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "  return estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNzleH_urqeW",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Functions for BERT (With and Without Image)\n",
        "\n",
        "*   CTX = 0 for English Premise and Hindi Hypothesis\n",
        "*   CTX = 1 for Hindi Premise and English Hypothesis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhGSEfgu2DE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def evaluate_and_get_hidden_context(estimator,input_fn_for_test,input_fn_for_hidden,is_progressive = False,hidden_context=None):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        " \n",
        "  if not is_progressive:\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "      features=input_fn_for_test,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "     \n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    hidden_input_fn = run_classifier.input_fn_builder(\n",
        "        features=input_fn_for_hidden,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "    res = estimator.predict(hidden_input_fn)\n",
        "    hidden_context = []\n",
        "    for i in res:\n",
        "      hidden_context.append(i[\"hidden_context\"])\n",
        "    hidden_context = np.array(hidden_context)\n",
        "    return hidden_context\n",
        "  else:\n",
        "    test_input_fn = input_fn_builder(\n",
        "      features=input_fn_for_test,\n",
        "      hidden_context=hidden_context,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "'''\n",
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate_and_get_hidden_context(ctx,estimator,input_fn_for_test,input_fn_for_hidden,is_progressive = False,hidden_context=None):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        "  if not is_progressive:\n",
        "    test_input_fn = run_classifier.input_fn_builder(\n",
        "      features=input_fn_for_test,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "    actual_labels = []\n",
        "    if ctx ==0:\n",
        "      for i in test_eng_hindi['label']:\n",
        "        actual_labels.append(i)\n",
        "    elif ctx==1:\n",
        "      for i in test_hindi_eng['label']:\n",
        "        actual_labels.append(i)\n",
        "\n",
        "    res = estimator.predict(test_input_fn)\n",
        "    predicted_labels = []\n",
        "\n",
        "    for i in res:\n",
        "      predicted_labels.append(i['labels'])\n",
        "    print(f'acc {accuracy_score(actual_labels,predicted_labels)} ')\n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    hidden_input_fn = run_classifier.input_fn_builder(\n",
        "        features=input_fn_for_hidden,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "    estimator.evaluate(input_fn=hidden_input_fn, steps=None)\n",
        "    res_ = estimator.predict(hidden_input_fn)\n",
        "    hidden_context = []\n",
        "    k = 0\n",
        "    try:\n",
        "      for i in res_:\n",
        "        #print(i['hidden_context'])\n",
        "        \n",
        "        hidden_context.append(i[\"hidden_context\"])\n",
        "        k+=1\n",
        "    except:\n",
        "      print(f'k is {k}')\n",
        "    hidden_context = np.array(hidden_context)\n",
        "    return hidden_context,actual_labels,predicted_labels\n",
        "  else:\n",
        "    test_input_fn = input_fn_builder(\n",
        "      features=input_fn_for_test,\n",
        "      hidden_context=hidden_context,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    actual_labels = []\n",
        "    if ctx ==0:\n",
        "      for i in test_eng_hindi['label']:\n",
        "        actual_labels.append(i)\n",
        "    elif ctx==1:\n",
        "      for i in test_hindi_eng['label']:\n",
        "        actual_labels.append(i)\n",
        "\n",
        "    res = estimator.predict(test_input_fn)\n",
        "    predicted_labels = []\n",
        "\n",
        "    for i in res:\n",
        "      predicted_labels.append(i['labels'])\n",
        "    return actual_labels,predicted_labels\n",
        "\n",
        "\n",
        "\n",
        "#IMG\n",
        "def evaluate_and_get_hidden_context_img(ctx,img_features_for_test,img_features,estimator,input_fn_for_test,input_fn_for_hidden,is_progressive = False,hidden_context=None):\n",
        "  MAX_SEQ_LENGTH = 128\n",
        " \n",
        "  if not is_progressive:\n",
        "    test_input_fn = input_fn_builder_img(\n",
        "      features=input_fn_for_test,\n",
        "      img_features = img_features_for_test,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "    actual_labels = []\n",
        "    if ctx ==0:\n",
        "      for i in test_eng_hindi['label']:\n",
        "        actual_labels.append(i)\n",
        "    elif ctx==1:\n",
        "      for i in test_hindi_eng['label']:\n",
        "        actual_labels.append(i)\n",
        "    res = estimator.predict(test_input_fn)\n",
        "    predicted_labels = []\n",
        "    for i in res:\n",
        "      predicted_labels.append(i['labels'])\n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    hidden_input_fn = input_fn_builder_img(\n",
        "        features=input_fn_for_hidden,\n",
        "        img_features = img_features,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        "    \n",
        "    res = estimator.predict(hidden_input_fn)\n",
        "    hidden_context = []\n",
        "    for i in res:\n",
        "      hidden_context.append(i[\"hidden_context\"])\n",
        "    hidden_context = np.array(hidden_context)\n",
        "    return hidden_context, actual_labels,predicted_labels\n",
        "  else:\n",
        "    test_input_fn = input_fn_builder_pr_img(\n",
        "      img_features = img_features_for_test,\n",
        "      features=input_fn_for_test,\n",
        "      hidden_context=hidden_context,\n",
        "      seq_length=MAX_SEQ_LENGTH,\n",
        "      is_training=False,\n",
        "      drop_remainder=False)\n",
        "    estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
        "    actual_labels = []\n",
        "    if ctx ==0:\n",
        "      for i in test_eng_hindi['label']:\n",
        "        actual_labels.append(i)\n",
        "    elif ctx==1:\n",
        "      for i in test_hindi_eng['label']:\n",
        "        actual_labels.append(i)\n",
        "\n",
        "    res = estimator.predict(test_input_fn)\n",
        "    predicted_labels = []\n",
        "\n",
        "    for i in res:\n",
        "      predicted_labels.append(i['labels'])\n",
        "    return actual_labels,predicted_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgByV60krqcD",
        "colab_type": "text"
      },
      "source": [
        "# Training for English Premise and Hindi Hypothesis\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUBrZX9Au4O1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "98657f8c-d637-4283-858b-6c048ba3f6d1"
      },
      "source": [
        "estimator = train('out_dir_train_engg',train_features_eng,input_fn_builder_progressive = False,hidden_context = None)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "321\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'out_dir_train_engg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 15000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe09f8ae9b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into out_dir_train_engg/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.4166437, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.52139\n",
            "INFO:tensorflow:loss = 1.1105239, step = 100 (65.730 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.11663\n",
            "INFO:tensorflow:loss = 1.1354445, step = 200 (47.245 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.11436\n",
            "INFO:tensorflow:loss = 1.1094239, step = 300 (47.295 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 321 into out_dir_train_engg/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 1.1380303.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d_cFV20rqZs",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for English Premis and Hindi Hypothesis\n",
        "\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZxAAk2eu7FV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccfae0f0-4a8c-47b1-8376-0dc8cc708ff0"
      },
      "source": [
        "hidden_context_eng, act_lab, pred_lab = evaluate_and_get_hidden_context(0,estimator,input_fn_for_test = test_features_eng,input_fn_for_hidden = train_features_eng,is_progressive = False)\n",
        "\n",
        "np.array(act_lab).dump(open('EH_Actual_labels_Normal_Imageless.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('EH_Predicted_labels_Normal_Imageless.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('EH_Actual_labels_Normal_Imageless.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('EH_Predicted_labels_Normal_Imageless.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment']\n",
        "print('ENG-HINDI(NORMAL)')\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "acc 0.312 \n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-04T12:44:50Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-04-12:44:55\n",
            "INFO:tensorflow:Saving dict for global step 321: eval_accuracy = 0.312, eval_loss = 1.1030923, global_step = 321, loss = 1.1031156\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 321: out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-04T12:45:00Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-04-12:45:24\n",
            "INFO:tensorflow:Saving dict for global step 321: eval_accuracy = 0.33644444, eval_loss = 1.0995826, global_step = 321, loss = 1.0996165\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 321: out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_engg/model.ckpt-321\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "ENG-HINDI(NORMAL)\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Contradiction       0.31      0.99      0.48       157\n",
            "      Neutral       0.00      0.00      0.00       174\n",
            "   Entailment       0.00      0.00      0.00       169\n",
            "\n",
            "     accuracy                           0.31       500\n",
            "    macro avg       0.10      0.33      0.16       500\n",
            " weighted avg       0.10      0.31      0.15       500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GanYAAqACjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " hidden_input_fn = run_classifier.input_fn_builder(\n",
        "        features=train_features_eng,\n",
        "        seq_length=MAX_SEQ_LENGTH,\n",
        "        is_training=False,\n",
        "        drop_remainder=False)\n",
        " r = estimator.predict(hidden_input_fn,yield_single_examples=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUpwIxnDDm5D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "6310a593-3ec6-4673-cf00-40e11ffe2f36"
      },
      "source": [
        "\n",
        "l = []\n",
        "for i in r:\n",
        "  l.append(i['labels'])\n",
        "ll = []\n",
        "for i in l:\n",
        "  for j in i:\n",
        "    ll.append(j)\n",
        "ll.append(l[-1])\n",
        "print(accuracy_score(train_eng_hindi['label'],ll))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_eng/model.ckpt-322\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-b09f76d67a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKAqLkreAu2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c230776b-272c-4e07-ff52-c09a769496ad"
      },
      "source": [
        "l[0:10]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context'],\n",
              " ['probabilities', 'labels', 'hidden_context']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzTVJWfrBuxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98174b81-783d-4329-a0e3-a1a43ee709ee"
      },
      "source": [
        "len(train_eng_hindi)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4509"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FzguDQtG3Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ6Ca80E91vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(hidden_context_eng).dump(open('Hidden_Context_English_Normal.npy', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_-8d8VPrqX-",
        "colab_type": "text"
      },
      "source": [
        "# Training for Spanish Premise and French Hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkc3Z6qhu9G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator = train('out_dir_train_hindi',train_features_hindi,input_fn_builder_progressive = False,hidden_context = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXg8xgK3rqIP",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for Spanish Premise and French Hypothesis\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WCIjhQ8u_iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_context_hindi, act_lab, pred_lab = evaluate_and_get_hidden_context(1,estimator,input_fn_for_test = test_features_hindi,input_fn_for_hidden = train_features_hindi,is_progressive = False)\n",
        "\n",
        "np.array(act_lab).dump(open('HE_Actual_labels_Normal_Imageless.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('HE_Predicted_labels_Normal_Imageless.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('HE_Actual_labels_Normal_Imageless.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('HE_Predicted_labels_Normal_Imageless.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print('SPANISH-FRENCH(NORMAL)')\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTO-WEAK9pfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(hidden_context_hindi).dump(open('Hidden_Context_Hindi_Normal.npy', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjdlPxj0s1wD",
        "colab_type": "text"
      },
      "source": [
        "# Progressive Training on English Premise and Hindi Hypothesis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFQdoMANvEq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_context_hindi = np.load('Hidden_Context_Hindi_Normal.npy', allow_pickle=True)\n",
        "estimator = train('out_dir_train_eng_pro',train_features_eng,input_fn_builder_progressive = True,hidden_context = hidden_context_hindi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMrJfOUys1tx",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for English Premis and Hindi Hypothesis (Progressive Variant)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "takvo4rVvGw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_batch_size = 501\n",
        "dummy = np.random.randn(Test_batch_size,768)\n",
        "act_lab, pred_lab = evaluate_and_get_hidden_context(0,estimator,input_fn_for_test = test_features_eng,input_fn_for_hidden = train_features_eng,is_progressive = True,hidden_context=dummy)\n",
        "\n",
        "np.array(act_lab).dump(open('EH_Actual_labels_Progressive_Imageless.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('EH_Predicted_labels_Progressive_Imageless.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('EH_Actual_labels_Progressive_Imageless.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('EH_Predicted_labels_Progressive_Imageless.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print('ENG-HINDI(PR)')\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxceP_3gs1rS",
        "colab_type": "text"
      },
      "source": [
        "# Progressive Training on Spanish Premise and French Hypothesis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuGgv5tYvKEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_context_eng = np.load('Hidden_Context_English_Normal.npy', allow_pickle=True)\n",
        "estimator = train('out_dir_train_hindi_pro',train_features_hindi,input_fn_builder_progressive = True,hidden_context = hidden_context_eng)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx-U9Xcks1pC",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for Spanish Premise and French Hypothesis (Progressive Variant)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeyqesMxvM4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_batch_size = 501\n",
        "dummy = np.random.randn(Test_batch_size,768)\n",
        "act_lab, pred_lab = evaluate_and_get_hidden_context(1,estimator,input_fn_for_test = test_features_hindi,input_fn_for_hidden = train_features_hindi,is_progressive = True,hidden_context=dummy)\n",
        "\n",
        "np.array(act_lab).dump(open('HE_Actual_labels_Progressive_Imageless.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('HE_Predicted_labels_Progressive_Imageless.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('HE_Actual_labels_Progressive_Imageless.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('HE_Predicted_labels_Progressive_Imageless.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print('SPANISH-FRENCH(PR)')\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOyqgyDes1m5",
        "colab_type": "text"
      },
      "source": [
        "# Training for English Premise and Hindi Hypothesis (Image Included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8e5gxaKvSEV",
        "colab_type": "code",
        "outputId": "be3721a2-b0b6-4b6e-c689-91ed518f83bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator = train_img(train_img_features,'out_dir_train_eng_img',train_features_eng,input_fn_builder_progressive = False,hidden_context = None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11547\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'out_dir_train_eng_img', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 6000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe1f3045400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "Beginning Training!\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = img_features, shape = (?, 1536)\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into out_dir_train_eng_img/model.ckpt.\n",
            "INFO:tensorflow:loss = 1.3960258, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.52439\n",
            "INFO:tensorflow:loss = 1.2084734, step = 100 (65.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.11034\n",
            "INFO:tensorflow:loss = 1.2552836, step = 200 (47.385 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10885\n",
            "INFO:tensorflow:loss = 1.0869311, step = 300 (47.420 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10761\n",
            "INFO:tensorflow:loss = 1.0499004, step = 400 (47.447 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10753\n",
            "INFO:tensorflow:loss = 1.09632, step = 500 (47.450 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10617\n",
            "INFO:tensorflow:loss = 1.1581898, step = 600 (47.479 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10584\n",
            "INFO:tensorflow:loss = 0.9463069, step = 700 (47.487 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10543\n",
            "INFO:tensorflow:loss = 0.9439215, step = 800 (47.496 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10498\n",
            "INFO:tensorflow:loss = 0.9008378, step = 900 (47.507 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10515\n",
            "INFO:tensorflow:loss = 1.294668, step = 1000 (47.503 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10518\n",
            "INFO:tensorflow:loss = 0.9757413, step = 1100 (47.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1046\n",
            "INFO:tensorflow:loss = 0.7581142, step = 1200 (47.515 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10455\n",
            "INFO:tensorflow:loss = 0.76910245, step = 1300 (47.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.105\n",
            "INFO:tensorflow:loss = 0.85975075, step = 1400 (47.506 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1038\n",
            "INFO:tensorflow:loss = 0.65162605, step = 1500 (47.533 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10356\n",
            "INFO:tensorflow:loss = 0.89229804, step = 1600 (47.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10357\n",
            "INFO:tensorflow:loss = 1.0954021, step = 1700 (47.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10345\n",
            "INFO:tensorflow:loss = 0.95375824, step = 1800 (47.541 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10313\n",
            "INFO:tensorflow:loss = 0.84381473, step = 1900 (47.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10353\n",
            "INFO:tensorflow:loss = 1.1345589, step = 2000 (47.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10396\n",
            "INFO:tensorflow:loss = 0.8009338, step = 2100 (47.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10257\n",
            "INFO:tensorflow:loss = 0.75735825, step = 2200 (47.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10239\n",
            "INFO:tensorflow:loss = 0.9539131, step = 2300 (47.565 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10325\n",
            "INFO:tensorflow:loss = 0.86672306, step = 2400 (47.546 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10324\n",
            "INFO:tensorflow:loss = 0.5842848, step = 2500 (47.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10243\n",
            "INFO:tensorflow:loss = 0.8666226, step = 2600 (47.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10292\n",
            "INFO:tensorflow:loss = 0.77726203, step = 2700 (47.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10295\n",
            "INFO:tensorflow:loss = 0.78694713, step = 2800 (47.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10425\n",
            "INFO:tensorflow:loss = 0.4519265, step = 2900 (47.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10408\n",
            "INFO:tensorflow:loss = 0.6885866, step = 3000 (47.526 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1033\n",
            "INFO:tensorflow:loss = 0.6261478, step = 3100 (47.544 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10279\n",
            "INFO:tensorflow:loss = 0.6704235, step = 3200 (47.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10343\n",
            "INFO:tensorflow:loss = 0.59421295, step = 3300 (47.541 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10404\n",
            "INFO:tensorflow:loss = 0.60510725, step = 3400 (47.527 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1025\n",
            "INFO:tensorflow:loss = 0.6536967, step = 3500 (47.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10327\n",
            "INFO:tensorflow:loss = 0.5474025, step = 3600 (47.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10397\n",
            "INFO:tensorflow:loss = 0.6861053, step = 3700 (47.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10265\n",
            "INFO:tensorflow:loss = 0.67742246, step = 3800 (47.559 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10299\n",
            "INFO:tensorflow:loss = 0.52006996, step = 3900 (47.551 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10456\n",
            "INFO:tensorflow:loss = 0.91310406, step = 4000 (47.516 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10476\n",
            "INFO:tensorflow:loss = 0.6901881, step = 4100 (47.511 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10565\n",
            "INFO:tensorflow:loss = 0.4952043, step = 4200 (47.491 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10404\n",
            "INFO:tensorflow:loss = 0.8872887, step = 4300 (47.528 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10423\n",
            "INFO:tensorflow:loss = 0.7079275, step = 4400 (47.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10166\n",
            "INFO:tensorflow:loss = 0.42538944, step = 4500 (47.582 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10134\n",
            "INFO:tensorflow:loss = 0.6040855, step = 4600 (47.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10295\n",
            "INFO:tensorflow:loss = 0.6341328, step = 4700 (47.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10343\n",
            "INFO:tensorflow:loss = 0.42180094, step = 4800 (47.541 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10308\n",
            "INFO:tensorflow:loss = 0.47210094, step = 4900 (47.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10477\n",
            "INFO:tensorflow:loss = 0.32620686, step = 5000 (47.512 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10422\n",
            "INFO:tensorflow:loss = 0.2959333, step = 5100 (47.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10397\n",
            "INFO:tensorflow:loss = 0.45037597, step = 5200 (47.529 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10423\n",
            "INFO:tensorflow:loss = 0.42638874, step = 5300 (47.523 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10356\n",
            "INFO:tensorflow:loss = 0.6956641, step = 5400 (47.538 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10299\n",
            "INFO:tensorflow:loss = 0.376327, step = 5500 (47.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10232\n",
            "INFO:tensorflow:loss = 0.5699243, step = 5600 (47.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10288\n",
            "INFO:tensorflow:loss = 0.2753974, step = 5700 (47.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10269\n",
            "INFO:tensorflow:loss = 0.45486364, step = 5800 (47.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10328\n",
            "INFO:tensorflow:loss = 0.38981614, step = 5900 (47.545 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into out_dir_train_eng_img/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 1.32187\n",
            "INFO:tensorflow:loss = 0.3366397, step = 6000 (75.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10118\n",
            "INFO:tensorflow:loss = 0.47976732, step = 6100 (47.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10169\n",
            "INFO:tensorflow:loss = 0.3875297, step = 6200 (47.581 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10234\n",
            "INFO:tensorflow:loss = 0.28274426, step = 6300 (47.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10295\n",
            "INFO:tensorflow:loss = 0.49069515, step = 6400 (47.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1012\n",
            "INFO:tensorflow:loss = 0.31656593, step = 6500 (47.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10225\n",
            "INFO:tensorflow:loss = 0.45283896, step = 6600 (47.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10211\n",
            "INFO:tensorflow:loss = 0.58905536, step = 6700 (47.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10172\n",
            "INFO:tensorflow:loss = 0.43015936, step = 6800 (47.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10176\n",
            "INFO:tensorflow:loss = 0.61318403, step = 6900 (47.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10119\n",
            "INFO:tensorflow:loss = 0.31373563, step = 7000 (47.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10081\n",
            "INFO:tensorflow:loss = 0.5460361, step = 7100 (47.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10186\n",
            "INFO:tensorflow:loss = 0.3314244, step = 7200 (47.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10109\n",
            "INFO:tensorflow:loss = 0.68552965, step = 7300 (47.594 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10136\n",
            "INFO:tensorflow:loss = 0.22596955, step = 7400 (47.588 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10121\n",
            "INFO:tensorflow:loss = 0.5605214, step = 7500 (47.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10217\n",
            "INFO:tensorflow:loss = 0.4027855, step = 7600 (47.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10309\n",
            "INFO:tensorflow:loss = 0.28660846, step = 7700 (47.549 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10244\n",
            "INFO:tensorflow:loss = 0.40116018, step = 7800 (47.564 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10116\n",
            "INFO:tensorflow:loss = 0.2655533, step = 7900 (47.592 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10109\n",
            "INFO:tensorflow:loss = 0.124150716, step = 8000 (47.595 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10078\n",
            "INFO:tensorflow:loss = 0.10015333, step = 8100 (47.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1016\n",
            "INFO:tensorflow:loss = 0.3308215, step = 8200 (47.582 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10149\n",
            "INFO:tensorflow:loss = 0.40365505, step = 8300 (47.586 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10153\n",
            "INFO:tensorflow:loss = 0.24389555, step = 8400 (47.584 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10126\n",
            "INFO:tensorflow:loss = 0.1725978, step = 8500 (47.591 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1009\n",
            "INFO:tensorflow:loss = 0.38174513, step = 8600 (47.599 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10128\n",
            "INFO:tensorflow:loss = 0.14387007, step = 8700 (47.590 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10026\n",
            "INFO:tensorflow:loss = 0.33917046, step = 8800 (47.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10084\n",
            "INFO:tensorflow:loss = 0.15970436, step = 8900 (47.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10003\n",
            "INFO:tensorflow:loss = 0.2922975, step = 9000 (47.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.0999\n",
            "INFO:tensorflow:loss = 0.24816708, step = 9100 (47.622 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10009\n",
            "INFO:tensorflow:loss = 0.1081419, step = 9200 (47.616 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10019\n",
            "INFO:tensorflow:loss = 0.036011543, step = 9300 (47.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10126\n",
            "INFO:tensorflow:loss = 0.3706424, step = 9400 (47.591 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10027\n",
            "INFO:tensorflow:loss = 0.13215606, step = 9500 (47.613 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10018\n",
            "INFO:tensorflow:loss = 0.18964587, step = 9600 (47.615 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10227\n",
            "INFO:tensorflow:loss = 0.5324039, step = 9700 (47.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10209\n",
            "INFO:tensorflow:loss = 0.4385805, step = 9800 (47.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10207\n",
            "INFO:tensorflow:loss = 0.38766536, step = 9900 (47.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10224\n",
            "INFO:tensorflow:loss = 0.49439082, step = 10000 (47.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10115\n",
            "INFO:tensorflow:loss = 0.5580778, step = 10100 (47.593 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10179\n",
            "INFO:tensorflow:loss = 0.10410955, step = 10200 (47.578 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.1008\n",
            "INFO:tensorflow:loss = 0.22006008, step = 10300 (47.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10173\n",
            "INFO:tensorflow:loss = 0.57167035, step = 10400 (47.579 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10184\n",
            "INFO:tensorflow:loss = 0.28330413, step = 10500 (47.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10212\n",
            "INFO:tensorflow:loss = 0.20526847, step = 10600 (47.571 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10293\n",
            "INFO:tensorflow:loss = 0.15824394, step = 10700 (47.553 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10223\n",
            "INFO:tensorflow:loss = 0.17451961, step = 10800 (47.569 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10227\n",
            "INFO:tensorflow:loss = 0.5134902, step = 10900 (47.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10249\n",
            "INFO:tensorflow:loss = 0.084851645, step = 11000 (47.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10253\n",
            "INFO:tensorflow:loss = 0.34744665, step = 11100 (47.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10234\n",
            "INFO:tensorflow:loss = 0.13792023, step = 11200 (47.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10194\n",
            "INFO:tensorflow:loss = 0.2270759, step = 11300 (47.575 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10201\n",
            "INFO:tensorflow:loss = 0.26676312, step = 11400 (47.573 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.10194\n",
            "INFO:tensorflow:loss = 0.11527632, step = 11500 (47.575 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 11547 into out_dir_train_eng_img/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.092633.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOy7qpzvs1k5",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for English Premis and Hindi Hypothesis (Image Included)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC020yOpvUlF",
        "colab_type": "code",
        "outputId": "359567d1-5a64-4f35-a929-7e0c7a611d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "hidden_context_eng_img, act_lab, pred_lab = evaluate_and_get_hidden_context_img(0,test_img_features,train_img_features,estimator,input_fn_for_test = test_features_eng,input_fn_for_hidden = train_features_eng,is_progressive = False)\n",
        "\n",
        "np.array(act_lab).dump(open('EH_Actual_labels_Normal_Image_10.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('EH_Predicted_labels_Normal_Image_10.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('EH_Actual_labels_Normal_Image_10.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('EH_Predicted_labels_Normal_Image_10.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = img_features, shape = (?, 1536)\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_eng_img/model.ckpt-11547\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = img_features, shape = (?, 1536)\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-06-04T07:55:11Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_eng_img/model.ckpt-11547\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-06-04-07:55:31\n",
            "INFO:tensorflow:Saving dict for global step 11547: eval_accuracy = 0.6796549, eval_loss = 1.2643262, global_step = 11547, loss = 1.2658327\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11547: out_dir_train_eng_img/model.ckpt-11547\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = img_features, shape = (?, 1536)\n",
            "INFO:tensorflow:  name = input_ids, shape = (?, 128)\n",
            "INFO:tensorflow:  name = input_mask, shape = (?, 128)\n",
            "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from out_dir_train_eng_img/model.ckpt-11547\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Contradiction       0.71      0.70      0.70      1189\n",
            "      Neutral       0.61      0.62      0.61      1198\n",
            "   Entailment       0.72      0.73      0.72      1204\n",
            "        Other       0.00      0.00      0.00         2\n",
            "\n",
            "     accuracy                           0.68      3593\n",
            "    macro avg       0.51      0.51      0.51      3593\n",
            " weighted avg       0.68      0.68      0.68      3593\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l-pK9NL8cbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(hidden_context_eng_img).dump(open('/content/gdrive/My Drive/COLING 2020/Hidden_Context_English_Image_10.npy', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8owzp2uls1i4",
        "colab_type": "text"
      },
      "source": [
        "# Training for Hindi Premise and English Hypothesis (Image Included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdJDLGktvWKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_img_features = np.random.randn(450,1024)\n",
        "estimator = train_img(train_img_features,'out_dir_train_hindi_img',train_features_hindi,input_fn_builder_progressive = False,hidden_context = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK-jYTVXs1gg",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for Hindi Premis and English Hypothesis (Image Included)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLq9M8q3vZv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test_img_features = np.random.randn(50,1024)\n",
        "#evaluate_img_features = np.random.randn(450,1024)\n",
        "hidden_context_hindi_img, act_lab, pred_lab = evaluate_and_get_hidden_context_img(1,test_img_features,train_img_features,estimator,input_fn_for_test = test_features_hindi,input_fn_for_hidden = train_features_hindi,is_progressive = False)\n",
        "\n",
        "np.array(act_lab).dump(open('HE_Actual_labels_Normal_Image.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('HE_Predicted_labels_Normal_Image.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('HE_Actual_labels_Normal_Image.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('HE_Predicted_labels_Normal_Image.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep4PfIeF9Z--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(hidden_context_hindi_img).dump(open('Hidden_Context_Hindi_Image.npy', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7co-B9Is1eJ",
        "colab_type": "text"
      },
      "source": [
        "# Progressive Training for English Premise and Hindi Hypothesis (Image Included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKdUVTzGvat4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_context_hindi_img = np.load('/content/gdrive/My Drive/COLING 2020/Hidden_Context_Hindi_Image.npy', allow_pickle=True)\n",
        "estimator = train_img(train_img_features,'out_dir_train_eng_pro_img',train_features_eng,input_fn_builder_progressive = True, hidden_context = hidden_context_hindi_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygJUXSL4s1bl",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation and Hidden Context generation for English Premis and Hindi Hypothesis (Image Included) (Progressive Variant)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b5Uqutevdx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_batch_size = 3593    # Test Split Size\n",
        "\n",
        "dummy = np.random.randn(Test_batch_size,768)\n",
        "#test_img_features = np.random.randn(50,1024)\n",
        "#evaluate_img_features = np.random.randn(450,1024)\n",
        "act_lab, pred_lab = evaluate_and_get_hidden_context_img(0,test_img_features,train_img_features,estimator,input_fn_for_test = test_features_eng,input_fn_for_hidden = train_features_eng,is_progressive = True,hidden_context=dummy)\n",
        "\n",
        "np.array(act_lab).dump(open('EH_Actual_labels_Progressive_Image.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('EH_Predicted_labels_Progressive_Image.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('EH_Actual_labels_Progressive_Image.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('EH_Predicted_labels_Progressive_Image.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW2vRMk9tcM4",
        "colab_type": "text"
      },
      "source": [
        "# Progressive Training for Hindi Premise and English Hypothesis (Image Included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms9vQ59ZvtWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_context_eng_img = np.load('/content/gdrive/My Drive/COLING 2020/Hidden_Context_English_Image_10.npy', allow_pickle=True)\n",
        "estimator = train_img(train_img_features,'out_dir_train_hindi_pro_img',train_features_hindi,input_fn_builder_progressive = True, hidden_context = hidden_context_eng_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwYCT8IXs1ZN",
        "colab_type": "text"
      },
      "source": [
        "#  Evaluation and Hidden Context generation for Hindi Premis and English Hypothesis (Image Included) (Progressive Variant)\n",
        "*   Hidden Context Obtained\n",
        "*   Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pfHkqWrvu-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_batch_size = 3593  # Test Split Size\n",
        "\n",
        "dummy = np.random.randn(Test_batch_size,768)\n",
        "#test_img_features = np.random.randn(50,1024)\n",
        "#evaluate_img_features = np.random.randn(450,1024)\n",
        "act_lab, pred_lab = evaluate_and_get_hidden_context_img(1,test_img_features,train_img_features,estimator,input_fn_for_test = test_features_hindi,input_fn_for_hidden = train_features_eng,is_progressive = True,hidden_context=dummy)\n",
        "\n",
        "np.array(act_lab).dump(open('HE_Actual_labels_Progressive_Image_10.npy', 'wb'))\n",
        "np.array(pred_lab).dump(open('HE_Predicted_labels_Progressive_Image_10.npy', 'wb'))\n",
        "\n",
        "y_true = list(np.load('HE_Actual_labels_Progressive_Image_10.npy', allow_pickle=True))\n",
        "y_pred = list(np.load('HE_Predicted_labels_Progressive_Image_10.npy', allow_pickle=True))\n",
        "target_names = ['Contradiction', 'Neutral', 'Entailment','Other']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}