{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhK4pbEaUCVb",
        "outputId": "f804c12c-30f5-43dd-ce0a-df8f18d213cb"
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3rqDiXyT6iT",
        "outputId": "6bffe22b-03bd-4bb6-b7c0-ee686c40681c"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.10.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 49.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.33.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.0)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.18.5)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0) (50.3.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2020.11.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=5ee646e07a152d2cc21223d6a567d2fb083c79aac4962b8ea5e4a9a3edfd8735\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, keras-applications, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koTe7z56UH2P",
        "outputId": "055084f1-978f-4bc2-a0f4-a5e402b4c6ca"
      },
      "source": [
        "!pip install keras-tuner==1.0.0 --no-dependencies"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/93/5db8ac61f6547ce94b534a1cf614961a6e302559f0cdd1b37248052c9761/keras_tuner-1.0.0-py2.py3-none-any.whl (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 30.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 25.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 21.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51kB 22.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 16.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81kB 15.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 7.8MB/s \n",
            "\u001b[?25hInstalling collected packages: keras-tuner\n",
            "Successfully installed keras-tuner-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO7OSLAEUtnw",
        "outputId": "8cdf17dd-b0ca-4924-e246-041be0b6ff85"
      },
      "source": [
        "!pip install terminaltables colorama"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: keras-tuner 1.0.0 requires tensorflow>=2.0.0-beta1, which is not installed.\u001b[0m\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGTwjp8uUb4Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "import kerastuner as kt\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j6yNRe_Ug4L"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) =\\\n",
        "    tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAXrsG9vVOek"
      },
      "source": [
        "import numpy as np\n",
        "train_images = np.asarray(train_images, dtype=np.float32) / 255.0\n",
        "test_images = np.asarray(test_images, dtype=np.float32) / 255.0\n",
        "train_images = train_images.reshape(60000,784)\n",
        "test_images = test_images.reshape(10000,784)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GS3OBSoWU8g"
      },
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels)"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E9M96ygWKP9"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_images.astype(np.float32),\n",
        "                                              train_labels.astype(np.float32)))"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEZMOB9DWcFO",
        "outputId": "9cdb8492-449b-406c-95aa-e4740840693b"
      },
      "source": [
        "k = 0\n",
        "for i in dataset:\n",
        "  print(i)\n",
        "  if k==2:\n",
        "    break\n",
        "  k+=1"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: id=1018192, shape=(784,), dtype=float32, numpy=\n",
            "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
            "       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
            "       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n",
            "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
            "       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
            "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n",
            "       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n",
            "       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n",
            "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n",
            "       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n",
            "       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n",
            "       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
            "       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n",
            "       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n",
            "       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n",
            "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n",
            "       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n",
            "       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
            "       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
            "       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
            "       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
            "       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n",
            "       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n",
            "       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n",
            "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n",
            "       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n",
            "       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n",
            "       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n",
            "       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n",
            "       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n",
            "       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n",
            "       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.92941177,\n",
            "       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n",
            "       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n",
            "       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n",
            "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
            "       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
            "       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
            "       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
            "       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n",
            "       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n",
            "       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n",
            "       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n",
            "       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n",
            "       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n",
            "       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n",
            "       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n",
            "       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n",
            "       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n",
            "       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n",
            "       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n",
            "       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n",
            "       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n",
            "       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n",
            "       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n",
            "       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n",
            "       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n",
            "       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n",
            "       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n",
            "       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n",
            "       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n",
            "       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
            "       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
            "       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
            "       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
            "       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
            "       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n",
            "       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n",
            "       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n",
            "       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n",
            "       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n",
            "       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n",
            "       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n",
            "       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n",
            "       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n",
            "       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n",
            "       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n",
            "       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n",
            "       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n",
            "       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n",
            "       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n",
            "       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n",
            "       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n",
            "       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n",
            "       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n",
            "       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n",
            "       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n",
            "       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n",
            "       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
            "       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        ], dtype=float32)>, <tf.Tensor: id=1018193, shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)>)\n",
            "(<tf.Tensor: id=1018194, shape=(784,), dtype=float32, numpy=\n",
            "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.16078432, 0.7372549 , 0.40392157, 0.21176471, 0.1882353 ,\n",
            "       0.16862746, 0.34117648, 0.65882355, 0.52156866, 0.0627451 ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
            "       0.19215687, 0.53333336, 0.85882354, 0.84705883, 0.89411765,\n",
            "       0.9254902 , 1.        , 1.        , 1.        , 1.        ,\n",
            "       0.8509804 , 0.84313726, 0.99607843, 0.90588236, 0.627451  ,\n",
            "       0.1764706 , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.05490196, 0.6901961 , 0.87058824, 0.8784314 ,\n",
            "       0.83137256, 0.79607844, 0.7764706 , 0.76862746, 0.78431374,\n",
            "       0.84313726, 0.8       , 0.7921569 , 0.7882353 , 0.7882353 ,\n",
            "       0.7882353 , 0.81960785, 0.85490197, 0.8784314 , 0.6431373 ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.7372549 ,\n",
            "       0.85882354, 0.78431374, 0.7764706 , 0.7921569 , 0.7764706 ,\n",
            "       0.78039217, 0.78039217, 0.7882353 , 0.76862746, 0.7764706 ,\n",
            "       0.7764706 , 0.78431374, 0.78431374, 0.78431374, 0.78431374,\n",
            "       0.7882353 , 0.78431374, 0.88235295, 0.16078432, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.2       , 0.85882354, 0.78039217, 0.79607844,\n",
            "       0.79607844, 0.83137256, 0.93333334, 0.972549  , 0.98039216,\n",
            "       0.9607843 , 0.9764706 , 0.9647059 , 0.96862745, 0.9882353 ,\n",
            "       0.972549  , 0.92156863, 0.8117647 , 0.79607844, 0.79607844,\n",
            "       0.87058824, 0.54901963, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.45490196,\n",
            "       0.8862745 , 0.80784315, 0.8       , 0.8117647 , 0.8       ,\n",
            "       0.39607844, 0.29411766, 0.18431373, 0.28627452, 0.1882353 ,\n",
            "       0.19607843, 0.1764706 , 0.2       , 0.24705882, 0.44313726,\n",
            "       0.87058824, 0.7921569 , 0.80784315, 0.8627451 , 0.8784314 ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.78431374, 0.87058824, 0.81960785,\n",
            "       0.79607844, 0.84313726, 0.78431374, 0.        , 0.27450982,\n",
            "       0.38431373, 0.        , 0.40392157, 0.23137255, 0.26666668,\n",
            "       0.2784314 , 0.19215687, 0.        , 0.85882354, 0.80784315,\n",
            "       0.8392157 , 0.8235294 , 0.98039216, 0.14901961, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.96862745, 0.85490197, 0.83137256, 0.8235294 , 0.84313726,\n",
            "       0.8392157 , 0.        , 0.99607843, 0.9529412 , 0.54509807,\n",
            "       1.        , 0.68235296, 0.9843137 , 1.        , 0.8039216 ,\n",
            "       0.        , 0.84313726, 0.8509804 , 0.8392157 , 0.8156863 ,\n",
            "       0.8627451 , 0.37254903, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.1764706 , 0.8862745 , 0.8392157 ,\n",
            "       0.8392157 , 0.84313726, 0.8784314 , 0.8039216 , 0.        ,\n",
            "       0.16470589, 0.13725491, 0.23529412, 0.0627451 , 0.06666667,\n",
            "       0.04705882, 0.05098039, 0.27450982, 0.        , 0.7411765 ,\n",
            "       0.84705883, 0.83137256, 0.80784315, 0.83137256, 0.6117647 ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.6431373 , 0.92156863, 0.8392157 , 0.827451  , 0.8627451 ,\n",
            "       0.84705883, 0.7882353 , 0.20392157, 0.2784314 , 0.34901962,\n",
            "       0.36862746, 0.3254902 , 0.30588236, 0.27450982, 0.29803923,\n",
            "       0.36078432, 0.34117648, 0.80784315, 0.8117647 , 0.87058824,\n",
            "       0.8352941 , 0.85882354, 0.8156863 , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.41568628, 0.73333335,\n",
            "       0.8745098 , 0.92941177, 0.972549  , 0.827451  , 0.7764706 ,\n",
            "       0.9882353 , 0.98039216, 0.972549  , 0.9607843 , 0.972549  ,\n",
            "       0.9882353 , 0.99215686, 0.98039216, 0.9882353 , 0.9372549 ,\n",
            "       0.7882353 , 0.83137256, 0.88235295, 0.84313726, 0.75686276,\n",
            "       0.44313726, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.06666667, 0.21176471,\n",
            "       0.62352943, 0.87058824, 0.75686276, 0.8156863 , 0.7529412 ,\n",
            "       0.77254903, 0.78431374, 0.78431374, 0.78431374, 0.78431374,\n",
            "       0.7882353 , 0.79607844, 0.7647059 , 0.8235294 , 0.64705884,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.18431373, 0.88235295,\n",
            "       0.7529412 , 0.8392157 , 0.79607844, 0.80784315, 0.8       ,\n",
            "       0.8       , 0.8039216 , 0.80784315, 0.8       , 0.83137256,\n",
            "       0.77254903, 0.85490197, 0.41960785, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.00392157, 0.02352941,\n",
            "       0.        , 0.18039216, 0.83137256, 0.7647059 , 0.83137256,\n",
            "       0.7921569 , 0.80784315, 0.8039216 , 0.8       , 0.8039216 ,\n",
            "       0.80784315, 0.8       , 0.83137256, 0.78431374, 0.85490197,\n",
            "       0.35686275, 0.        , 0.01176471, 0.00392157, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.00392157, 0.        , 0.04313726,\n",
            "       0.77254903, 0.78039217, 0.8039216 , 0.7921569 , 0.8039216 ,\n",
            "       0.80784315, 0.8       , 0.8039216 , 0.8117647 , 0.8       ,\n",
            "       0.8039216 , 0.8039216 , 0.85490197, 0.3019608 , 0.        ,\n",
            "       0.01960784, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.01176471, 0.        , 0.00784314, 0.7490196 , 0.7764706 ,\n",
            "       0.7882353 , 0.8039216 , 0.80784315, 0.8039216 , 0.8039216 ,\n",
            "       0.80784315, 0.81960785, 0.80784315, 0.78039217, 0.81960785,\n",
            "       0.85882354, 0.2901961 , 0.        , 0.01960784, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.00784314, 0.        ,\n",
            "       0.        , 0.7372549 , 0.77254903, 0.78431374, 0.8117647 ,\n",
            "       0.8117647 , 0.8       , 0.8117647 , 0.8117647 , 0.8235294 ,\n",
            "       0.8156863 , 0.7764706 , 0.8117647 , 0.8666667 , 0.28235295,\n",
            "       0.        , 0.01568628, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.00784314, 0.        , 0.        , 0.84313726,\n",
            "       0.7764706 , 0.79607844, 0.80784315, 0.8156863 , 0.8039216 ,\n",
            "       0.8117647 , 0.8117647 , 0.8235294 , 0.8156863 , 0.78431374,\n",
            "       0.7921569 , 0.87058824, 0.29411766, 0.        , 0.01568628,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.        , 0.        , 0.83137256, 0.7764706 , 0.81960785,\n",
            "       0.80784315, 0.81960785, 0.80784315, 0.8156863 , 0.8117647 ,\n",
            "       0.827451  , 0.80784315, 0.8039216 , 0.7764706 , 0.8666667 ,\n",
            "       0.3137255 , 0.        , 0.01176471, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
            "       0.8       , 0.7882353 , 0.8039216 , 0.8156863 , 0.8117647 ,\n",
            "       0.8039216 , 0.827451  , 0.8039216 , 0.8235294 , 0.8235294 ,\n",
            "       0.81960785, 0.7647059 , 0.8666667 , 0.3764706 , 0.        ,\n",
            "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.00392157, 0.        , 0.        , 0.7921569 , 0.7882353 ,\n",
            "       0.8039216 , 0.81960785, 0.8117647 , 0.8039216 , 0.8352941 ,\n",
            "       0.80784315, 0.8235294 , 0.81960785, 0.8235294 , 0.7607843 ,\n",
            "       0.8509804 , 0.4117647 , 0.        , 0.00784314, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
            "       0.        , 0.8       , 0.8       , 0.8039216 , 0.8156863 ,\n",
            "       0.8117647 , 0.8039216 , 0.84313726, 0.8117647 , 0.8235294 ,\n",
            "       0.8156863 , 0.827451  , 0.75686276, 0.8352941 , 0.4509804 ,\n",
            "       0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.8       ,\n",
            "       0.8117647 , 0.8117647 , 0.8156863 , 0.80784315, 0.80784315,\n",
            "       0.84313726, 0.8235294 , 0.8235294 , 0.8117647 , 0.83137256,\n",
            "       0.7647059 , 0.8235294 , 0.4627451 , 0.        , 0.00784314,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.        , 0.        , 0.7764706 , 0.8156863 , 0.8156863 ,\n",
            "       0.8156863 , 0.8       , 0.8117647 , 0.83137256, 0.83137256,\n",
            "       0.8235294 , 0.8117647 , 0.827451  , 0.76862746, 0.8117647 ,\n",
            "       0.4745098 , 0.        , 0.00392157, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
            "       0.7764706 , 0.8235294 , 0.8117647 , 0.8156863 , 0.80784315,\n",
            "       0.81960785, 0.8352941 , 0.83137256, 0.827451  , 0.8117647 ,\n",
            "       0.8235294 , 0.77254903, 0.8117647 , 0.4862745 , 0.        ,\n",
            "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.6745098 , 0.8235294 ,\n",
            "       0.79607844, 0.7882353 , 0.78039217, 0.8       , 0.8117647 ,\n",
            "       0.8039216 , 0.8       , 0.7882353 , 0.8039216 , 0.77254903,\n",
            "       0.80784315, 0.49803922, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.7372549 , 0.8666667 , 0.8392157 , 0.91764706,\n",
            "       0.9254902 , 0.93333334, 0.95686275, 0.95686275, 0.95686275,\n",
            "       0.9411765 , 0.9529412 , 0.8392157 , 0.8784314 , 0.63529414,\n",
            "       0.        , 0.00784314, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.00392157, 0.        , 0.        , 0.54509807,\n",
            "       0.57254905, 0.50980395, 0.5294118 , 0.5294118 , 0.5372549 ,\n",
            "       0.49019608, 0.4862745 , 0.49019608, 0.4745098 , 0.46666667,\n",
            "       0.44705883, 0.50980395, 0.29803923, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        ], dtype=float32)>, <tf.Tensor: id=1018195, shape=(10,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)\n",
            "(<tf.Tensor: id=1018196, shape=(784,), dtype=float32, numpy=\n",
            "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.08627451,\n",
            "       0.4627451 , 0.09411765, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.1882353 , 0.34509805, 0.01960784,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.04705882, 0.39215687, 0.83137256, 0.8039216 ,\n",
            "       0.7254902 , 0.7019608 , 0.6784314 , 0.7294118 , 0.75686276,\n",
            "       0.8666667 , 0.5568628 , 0.33333334, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.33333334, 0.29803923, 0.78039217, 0.88235295, 0.972549  ,\n",
            "       1.        , 0.93333334, 0.8862745 , 0.6156863 , 0.26666668,\n",
            "       0.3137255 , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.35686275, 0.27058825,\n",
            "       0.35686275, 0.7882353 , 0.85490197, 0.88235295, 0.81960785,\n",
            "       0.61960787, 0.23921569, 0.3647059 , 0.28235295, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.30980393, 0.34901962, 0.23921569, 0.23137255,\n",
            "       0.34117648, 0.42352942, 0.29411766, 0.21960784, 0.29803923,\n",
            "       0.38039216, 0.28627452, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
            "       0.34901962, 0.3137255 , 0.3137255 , 0.2627451 , 0.24705882,\n",
            "       0.28627452, 0.3254902 , 0.3137255 , 0.3764706 , 0.28235295,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.3019608 , 0.34509805, 0.3019608 ,\n",
            "       0.3137255 , 0.3254902 , 0.3254902 , 0.3254902 , 0.3254902 ,\n",
            "       0.31764707, 0.37254903, 0.29803923, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.34901962, 0.3764706 , 0.3137255 , 0.3254902 , 0.31764707,\n",
            "       0.32941177, 0.33333334, 0.33333334, 0.33333334, 0.38039216,\n",
            "       0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.3647059 , 0.38039216,\n",
            "       0.31764707, 0.33333334, 0.32941177, 0.33333334, 0.34117648,\n",
            "       0.34509805, 0.32941177, 0.3882353 , 0.34117648, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.37254903, 0.34117648, 0.32941177, 0.34117648,\n",
            "       0.34509805, 0.33333334, 0.34117648, 0.34117648, 0.32941177,\n",
            "       0.36078432, 0.34117648, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.38039216,\n",
            "       0.34117648, 0.34117648, 0.33333334, 0.34509805, 0.34117648,\n",
            "       0.34117648, 0.34117648, 0.34509805, 0.33333334, 0.41960785,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.06666667, 0.39215687, 0.34509805, 0.34117648,\n",
            "       0.34117648, 0.34509805, 0.34117648, 0.34117648, 0.33333334,\n",
            "       0.34901962, 0.3019608 , 0.4627451 , 0.03137255, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.03921569,\n",
            "       0.3647059 , 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
            "       0.34117648, 0.34509805, 0.34117648, 0.34901962, 0.3137255 ,\n",
            "       0.40392157, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.03529412, 0.3764706 , 0.34117648,\n",
            "       0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.34509805,\n",
            "       0.34117648, 0.34509805, 0.34117648, 0.40392157, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.04705882, 0.3764706 , 0.33333334, 0.34117648, 0.34117648,\n",
            "       0.34117648, 0.33333334, 0.34117648, 0.34117648, 0.34509805,\n",
            "       0.34901962, 0.39215687, 0.00784314, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.07843138, 0.37254903,\n",
            "       0.32941177, 0.34509805, 0.33333334, 0.34117648, 0.34509805,\n",
            "       0.34509805, 0.34509805, 0.34901962, 0.34509805, 0.3882353 ,\n",
            "       0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.08235294, 0.3764706 , 0.33333334, 0.34117648,\n",
            "       0.33333334, 0.34509805, 0.34509805, 0.34509805, 0.34509805,\n",
            "       0.34901962, 0.34901962, 0.3882353 , 0.03921569, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.09411765,\n",
            "       0.3764706 , 0.33333334, 0.34117648, 0.33333334, 0.34117648,\n",
            "       0.34509805, 0.34509805, 0.34901962, 0.34509805, 0.35686275,\n",
            "       0.4       , 0.05490196, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.09803922, 0.3647059 , 0.32941177,\n",
            "       0.34509805, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
            "       0.34117648, 0.34901962, 0.35686275, 0.40392157, 0.11372549,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.11764706, 0.37254903, 0.33333334, 0.34509805, 0.34509805,\n",
            "       0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.34901962,\n",
            "       0.34509805, 0.4       , 0.14509805, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.13333334, 0.3764706 ,\n",
            "       0.34509805, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
            "       0.34117648, 0.34117648, 0.33333334, 0.33333334, 0.38039216,\n",
            "       0.14901961, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.15686275, 0.3764706 , 0.34117648, 0.33333334,\n",
            "       0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.34117648,\n",
            "       0.33333334, 0.32941177, 0.36078432, 0.19215687, 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
            "       0.37254903, 0.3254902 , 0.32941177, 0.34117648, 0.34117648,\n",
            "       0.34117648, 0.34117648, 0.34117648, 0.34117648, 0.32941177,\n",
            "       0.34117648, 0.32941177, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.28235295, 0.37254903, 0.33333334,\n",
            "       0.32941177, 0.33333334, 0.34509805, 0.34117648, 0.34117648,\n",
            "       0.34901962, 0.34117648, 0.33333334, 0.3254902 , 0.24705882,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.2509804 , 0.39215687, 0.32941177, 0.34117648, 0.34509805,\n",
            "       0.33333334, 0.34509805, 0.34509805, 0.32941177, 0.34117648,\n",
            "       0.3254902 , 0.37254903, 0.20784314, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.03921569, 0.4       ,\n",
            "       0.39215687, 0.35686275, 0.35686275, 0.34901962, 0.33333334,\n",
            "       0.32941177, 0.32941177, 0.34117648, 0.42352942, 0.41568628,\n",
            "       0.05490196, 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.03137255, 0.28627452, 0.3647059 ,\n",
            "       0.40784314, 0.41960785, 0.40392157, 0.40392157, 0.41568628,\n",
            "       0.4       , 0.29411766, 0.03921569, 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
            "       0.        , 0.        , 0.        , 0.07058824, 0.16470589,\n",
            "       0.22352941, 0.21960784, 0.1254902 , 0.03137255, 0.        ,\n",
            "       0.        , 0.00392157, 0.        , 0.        , 0.        ,\n",
            "       0.        , 0.        , 0.        , 0.        ], dtype=float32)>, <tf.Tensor: id=1018197, shape=(10,), dtype=float32, numpy=array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSWCQKl0nJ_B"
      },
      "source": [
        "!rm -rf results\n"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkMkiFBaw-K2"
      },
      "source": [
        "class my_layer(tf.keras.layers.Layer):\n",
        "  \n",
        "  def __init__(self,ou):\n",
        "    super(my_layer,self).__init__()\n",
        "    \n",
        "    \n",
        "    self.W = tf.Variable(initial_value=np.random.randn(784,ou),trainable = True, dtype = tf.float32)\n",
        "  def call(self,inputs):\n",
        "    \n",
        "    return tf.nn.relu(tf.matmul(inputs,self.W))"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbYJJMOSWhJv"
      },
      "source": [
        "def build_model(hp):\n",
        "  \"\"\"Builds a dnn model.\"\"\"\n",
        "  class mod(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super(mod,self).__init__()\n",
        "      ou = hp.Int('nou', 120, 200, step=20, default=120)\n",
        "      ou1 = hp.Int('nou_w', 120, 200, step=20, default=120)\n",
        "      self.layer0 = my_layer(ou1)\n",
        "      self.layer1 = tf.keras.layers.Dense(ou,activation = tf.nn.relu)\n",
        "      self.layer2 = tf.keras.layers.Dense(10,activation = tf.nn.softmax)\n",
        "    def call(self,inputs):\n",
        "      return self.layer2(self.layer1(self.layer0(inputs)))\n",
        "  model = mod()\n",
        "  \n",
        "  return model\n",
        "  \n",
        " "
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0rrlDaNlMCP"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=200):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "2I8_hJiOqHKb",
        "outputId": "34b3524f-75df-4ca9-e545-11185812206d"
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(512)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(4000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 298
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02JxXSfvQGM"
      },
      "source": [
        "def get_loss(lab,logits):\n",
        "  return tf.keras.losses.categorical_crossentropy(lab,logits)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ6IiqZ-X0bm"
      },
      "source": [
        "\n",
        "class MyTuner(kt.Tuner):\n",
        "\n",
        "    def run_trial(self, trial, train_ds):\n",
        "        hp = trial.hyperparameters\n",
        "        \n",
        "        # Hyperparameters can be added anywhere inside `run_trial`.\n",
        "        # When the first trial is run, they will take on their default values.\n",
        "        # Afterwards, they will be tuned by the `Oracle`.\n",
        "        \n",
        "        train_ds = train_ds.batch(\n",
        "            hp.Int('batch_size', 32, 128, step=32, default=64))\n",
        "        \n",
        "        model = self.hypermodel.build(trial.hyperparameters)\n",
        "        lr = CustomSchedule(512)\n",
        "        #lr = 0.001\n",
        "        optimizer = tf.keras.optimizers.Adam(lr, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "        epoch_loss_metric = tf.keras.metrics.Mean()\n",
        "        \n",
        "        @tf.function\n",
        "        def run_train_step(images,lab):\n",
        "            with tf.GradientTape() as t:\n",
        "              logits = model(images)\n",
        "              loss = tf.reduce_mean(get_loss(lab,logits))\n",
        "              grads = t.gradient(loss, model.trainable_variables)\n",
        "      \n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            epoch_loss_metric.update_state(loss)\n",
        "            return loss\n",
        "        # `self.on_epoch_end` reports results to the `Oracle` and saves the\n",
        "        # current state of the Model. The other hooks called here only log values\n",
        "        # for display but can also be overridden. For use cases where there is no\n",
        "        # natural concept of epoch, you do not have to call any of these hooks. In\n",
        "        # this case you should instead call `self.oracle.update_trial` and\n",
        "        # `self.oracle.save_model` manually.\n",
        "        for epoch in range(5):\n",
        "            print('Epoch: {}'.format(epoch))\n",
        "\n",
        "            #self.on_epoch_begin(trial, model, epoch, logs={})\n",
        "            for (batch, (images, lab)) in enumerate(train_ds):\n",
        "                \n",
        "                batch_loss = float(run_train_step(images,lab))\n",
        "                \n",
        "\n",
        "                if batch % 100 == 0:\n",
        "                    loss = epoch_loss_metric.result().numpy()\n",
        "                    print('Batch: {}, Average Loss: {}'.format(batch, loss))\n",
        "\n",
        "            epoch_loss = epoch_loss_metric.result().numpy()\n",
        "            self.on_epoch_end(trial, model, epoch, logs={'fin_loss': epoch_loss})\n",
        "            epoch_loss_metric.reset_states()\n"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PtL9HTbqZtT5",
        "outputId": "c655ad2d-2c21-48a5-dd0e-d1f14d123242"
      },
      "source": [
        "tuner = MyTuner(\n",
        "oracle=kt.oracles.BayesianOptimization(\n",
        "          objective=kt.Objective('fin_loss', 'min'),\n",
        "          max_trials=10),\n",
        "      hypermodel=build_model,\n",
        "      directory='results',\n",
        "      project_name='mnist_custom_training')\n",
        "\n",
        "\n",
        "tuner.search(train_ds=dataset)"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 12.076967239379883\n",
            "Batch: 100, Average Loss: 3.3560736179351807\n",
            "Batch: 200, Average Loss: 2.099210023880005\n",
            "Batch: 300, Average Loss: 1.6218373775482178\n",
            "Batch: 400, Average Loss: 1.3575841188430786\n",
            "Batch: 500, Average Loss: 1.1896796226501465\n",
            "Batch: 600, Average Loss: 1.070132851600647\n",
            "Batch: 700, Average Loss: 0.9815959334373474\n",
            "Batch: 800, Average Loss: 0.9140570759773254\n",
            "Batch: 900, Average Loss: 0.8631505370140076\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.26577359437942505\n",
            "Batch: 100, Average Loss: 0.4066585600376129\n",
            "Batch: 200, Average Loss: 0.3984401822090149\n",
            "Batch: 300, Average Loss: 0.39640510082244873\n",
            "Batch: 400, Average Loss: 0.39208269119262695\n",
            "Batch: 500, Average Loss: 0.3850157856941223\n",
            "Batch: 600, Average Loss: 0.3784024715423584\n",
            "Batch: 700, Average Loss: 0.37246814370155334\n",
            "Batch: 800, Average Loss: 0.3685401380062103\n",
            "Batch: 900, Average Loss: 0.3673023581504822\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.23862552642822266\n",
            "Batch: 100, Average Loss: 0.3299907147884369\n",
            "Batch: 200, Average Loss: 0.3246290683746338\n",
            "Batch: 300, Average Loss: 0.32564637064933777\n",
            "Batch: 400, Average Loss: 0.32292863726615906\n",
            "Batch: 500, Average Loss: 0.31954094767570496\n",
            "Batch: 600, Average Loss: 0.31500887870788574\n",
            "Batch: 700, Average Loss: 0.3116876780986786\n",
            "Batch: 800, Average Loss: 0.30889418721199036\n",
            "Batch: 900, Average Loss: 0.30914920568466187\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.19567465782165527\n",
            "Batch: 100, Average Loss: 0.28673288226127625\n",
            "Batch: 200, Average Loss: 0.28332459926605225\n",
            "Batch: 300, Average Loss: 0.2858629822731018\n",
            "Batch: 400, Average Loss: 0.28347182273864746\n",
            "Batch: 500, Average Loss: 0.2816345691680908\n",
            "Batch: 600, Average Loss: 0.2776758670806885\n",
            "Batch: 700, Average Loss: 0.2746412754058838\n",
            "Batch: 800, Average Loss: 0.2722918391227722\n",
            "Batch: 900, Average Loss: 0.27325817942619324\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.1904398500919342\n",
            "Batch: 100, Average Loss: 0.25568094849586487\n",
            "Batch: 200, Average Loss: 0.25409871339797974\n",
            "Batch: 300, Average Loss: 0.2572983503341675\n",
            "Batch: 400, Average Loss: 0.2555330693721771\n",
            "Batch: 500, Average Loss: 0.2542478144168854\n",
            "Batch: 600, Average Loss: 0.2506997883319855\n",
            "Batch: 700, Average Loss: 0.24777574837207794\n",
            "Batch: 800, Average Loss: 0.24599577486515045\n",
            "Batch: 900, Average Loss: 0.24735313653945923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 200</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.2471131831407547</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 12.097491264343262\n",
            "Batch: 100, Average Loss: 3.01611590385437\n",
            "Batch: 200, Average Loss: 1.9168646335601807\n",
            "Batch: 300, Average Loss: 1.4915225505828857\n",
            "Batch: 400, Average Loss: 1.249793529510498\n",
            "Batch: 500, Average Loss: 1.0968410968780518\n",
            "Batch: 600, Average Loss: 0.9915791749954224\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.31301358342170715\n",
            "Batch: 100, Average Loss: 0.4208567440509796\n",
            "Batch: 200, Average Loss: 0.4102117419242859\n",
            "Batch: 300, Average Loss: 0.40157651901245117\n",
            "Batch: 400, Average Loss: 0.39401674270629883\n",
            "Batch: 500, Average Loss: 0.38698291778564453\n",
            "Batch: 600, Average Loss: 0.38227689266204834\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.2318422794342041\n",
            "Batch: 100, Average Loss: 0.33225375413894653\n",
            "Batch: 200, Average Loss: 0.32803428173065186\n",
            "Batch: 300, Average Loss: 0.3229156732559204\n",
            "Batch: 400, Average Loss: 0.3193384110927582\n",
            "Batch: 500, Average Loss: 0.31584101915359497\n",
            "Batch: 600, Average Loss: 0.3140746057033539\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.1760903149843216\n",
            "Batch: 100, Average Loss: 0.2846503257751465\n",
            "Batch: 200, Average Loss: 0.28284478187561035\n",
            "Batch: 300, Average Loss: 0.2782272398471832\n",
            "Batch: 400, Average Loss: 0.27658143639564514\n",
            "Batch: 500, Average Loss: 0.2740998864173889\n",
            "Batch: 600, Average Loss: 0.2731788456439972\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.16475869715213776\n",
            "Batch: 100, Average Loss: 0.2484876662492752\n",
            "Batch: 200, Average Loss: 0.24932320415973663\n",
            "Batch: 300, Average Loss: 0.24535755813121796\n",
            "Batch: 400, Average Loss: 0.24508090317249298\n",
            "Batch: 500, Average Loss: 0.2427067756652832\n",
            "Batch: 600, Average Loss: 0.24236930906772614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 96</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 200</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.24260877072811127</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 13.63520336151123\n",
            "Batch: 100, Average Loss: 3.2873456478118896\n",
            "Batch: 200, Average Loss: 2.0410690307617188\n",
            "Batch: 300, Average Loss: 1.5752248764038086\n",
            "Batch: 400, Average Loss: 1.3173646926879883\n",
            "Batch: 500, Average Loss: 1.152150273323059\n",
            "Batch: 600, Average Loss: 1.0394786596298218\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.3330496847629547\n",
            "Batch: 100, Average Loss: 0.4405684769153595\n",
            "Batch: 200, Average Loss: 0.43040379881858826\n",
            "Batch: 300, Average Loss: 0.41970691084861755\n",
            "Batch: 400, Average Loss: 0.41045233607292175\n",
            "Batch: 500, Average Loss: 0.4018324613571167\n",
            "Batch: 600, Average Loss: 0.39561957120895386\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.25329867005348206\n",
            "Batch: 100, Average Loss: 0.3478280007839203\n",
            "Batch: 200, Average Loss: 0.3494602143764496\n",
            "Batch: 300, Average Loss: 0.3440748155117035\n",
            "Batch: 400, Average Loss: 0.33864161372184753\n",
            "Batch: 500, Average Loss: 0.33348000049591064\n",
            "Batch: 600, Average Loss: 0.33074429631233215\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.22614502906799316\n",
            "Batch: 100, Average Loss: 0.3041439950466156\n",
            "Batch: 200, Average Loss: 0.30649101734161377\n",
            "Batch: 300, Average Loss: 0.30225545167922974\n",
            "Batch: 400, Average Loss: 0.2983234226703644\n",
            "Batch: 500, Average Loss: 0.294393390417099\n",
            "Batch: 600, Average Loss: 0.2927728295326233\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.2050517052412033\n",
            "Batch: 100, Average Loss: 0.27438655495643616\n",
            "Batch: 200, Average Loss: 0.2779928147792816\n",
            "Batch: 300, Average Loss: 0.2734815180301666\n",
            "Batch: 400, Average Loss: 0.2700616121292114\n",
            "Batch: 500, Average Loss: 0.2668478786945343\n",
            "Batch: 600, Average Loss: 0.2657170593738556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 96</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.26550161838531494</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 18.19675064086914\n",
            "Batch: 100, Average Loss: 4.323172092437744\n",
            "Batch: 200, Average Loss: 2.5750367641448975\n",
            "Batch: 300, Average Loss: 1.9258428812026978\n",
            "Batch: 400, Average Loss: 1.5789939165115356\n",
            "Batch: 500, Average Loss: 1.3606324195861816\n",
            "Batch: 600, Average Loss: 1.2109159231185913\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.3409848213195801\n",
            "Batch: 100, Average Loss: 0.43158161640167236\n",
            "Batch: 200, Average Loss: 0.4275985658168793\n",
            "Batch: 300, Average Loss: 0.41324275732040405\n",
            "Batch: 400, Average Loss: 0.40489304065704346\n",
            "Batch: 500, Average Loss: 0.39608901739120483\n",
            "Batch: 600, Average Loss: 0.3911406695842743\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.24610395729541779\n",
            "Batch: 100, Average Loss: 0.34051287174224854\n",
            "Batch: 200, Average Loss: 0.34297415614128113\n",
            "Batch: 300, Average Loss: 0.33645665645599365\n",
            "Batch: 400, Average Loss: 0.3328079879283905\n",
            "Batch: 500, Average Loss: 0.3281305730342865\n",
            "Batch: 600, Average Loss: 0.326603502035141\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.1923971027135849\n",
            "Batch: 100, Average Loss: 0.29931575059890747\n",
            "Batch: 200, Average Loss: 0.30247071385383606\n",
            "Batch: 300, Average Loss: 0.29727476835250854\n",
            "Batch: 400, Average Loss: 0.2942216694355011\n",
            "Batch: 500, Average Loss: 0.29106423258781433\n",
            "Batch: 600, Average Loss: 0.2904699146747589\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.17118476331233978\n",
            "Batch: 100, Average Loss: 0.2705860435962677\n",
            "Batch: 200, Average Loss: 0.2734523117542267\n",
            "Batch: 300, Average Loss: 0.26859742403030396\n",
            "Batch: 400, Average Loss: 0.26662832498550415\n",
            "Batch: 500, Average Loss: 0.264400452375412\n",
            "Batch: 600, Average Loss: 0.264084130525589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 96</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.26329633593559265</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 9.793546676635742\n",
            "Batch: 100, Average Loss: 3.2947356700897217\n",
            "Batch: 200, Average Loss: 2.1552977561950684\n",
            "Batch: 300, Average Loss: 1.699903130531311\n",
            "Batch: 400, Average Loss: 1.429388403892517\n",
            "Batch: 500, Average Loss: 1.2572003602981567\n",
            "Batch: 600, Average Loss: 1.1430078744888306\n",
            "Batch: 700, Average Loss: 1.0533990859985352\n",
            "Batch: 800, Average Loss: 0.986462414264679\n",
            "Batch: 900, Average Loss: 0.928889274597168\n",
            "Batch: 1000, Average Loss: 0.8807727694511414\n",
            "Batch: 1100, Average Loss: 0.8419824838638306\n",
            "Batch: 1200, Average Loss: 0.81171053647995\n",
            "Batch: 1300, Average Loss: 0.7833541631698608\n",
            "Batch: 1400, Average Loss: 0.7588273286819458\n",
            "Batch: 1500, Average Loss: 0.7375608682632446\n",
            "Batch: 1600, Average Loss: 0.7184645533561707\n",
            "Batch: 1700, Average Loss: 0.7025134563446045\n",
            "Batch: 1800, Average Loss: 0.6872672438621521\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.29323387145996094\n",
            "Batch: 100, Average Loss: 0.40205058455467224\n",
            "Batch: 200, Average Loss: 0.3979959189891815\n",
            "Batch: 300, Average Loss: 0.39554911851882935\n",
            "Batch: 400, Average Loss: 0.383786141872406\n",
            "Batch: 500, Average Loss: 0.3819274306297302\n",
            "Batch: 600, Average Loss: 0.38429898023605347\n",
            "Batch: 700, Average Loss: 0.3812097907066345\n",
            "Batch: 800, Average Loss: 0.3810853362083435\n",
            "Batch: 900, Average Loss: 0.37594887614250183\n",
            "Batch: 1000, Average Loss: 0.3723996877670288\n",
            "Batch: 1100, Average Loss: 0.3697686493396759\n",
            "Batch: 1200, Average Loss: 0.3695903718471527\n",
            "Batch: 1300, Average Loss: 0.36783117055892944\n",
            "Batch: 1400, Average Loss: 0.3663663864135742\n",
            "Batch: 1500, Average Loss: 0.3658445179462433\n",
            "Batch: 1600, Average Loss: 0.3645753264427185\n",
            "Batch: 1700, Average Loss: 0.36452680826187134\n",
            "Batch: 1800, Average Loss: 0.3635822832584381\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.29996562004089355\n",
            "Batch: 100, Average Loss: 0.339540958404541\n",
            "Batch: 200, Average Loss: 0.33409422636032104\n",
            "Batch: 300, Average Loss: 0.3326515555381775\n",
            "Batch: 400, Average Loss: 0.3225860297679901\n",
            "Batch: 500, Average Loss: 0.3225378096103668\n",
            "Batch: 600, Average Loss: 0.325332909822464\n",
            "Batch: 700, Average Loss: 0.3235625922679901\n",
            "Batch: 800, Average Loss: 0.32404786348342896\n",
            "Batch: 900, Average Loss: 0.3200429081916809\n",
            "Batch: 1000, Average Loss: 0.31797119975090027\n",
            "Batch: 1100, Average Loss: 0.3162700831890106\n",
            "Batch: 1200, Average Loss: 0.31646037101745605\n",
            "Batch: 1300, Average Loss: 0.3150584101676941\n",
            "Batch: 1400, Average Loss: 0.31418314576148987\n",
            "Batch: 1500, Average Loss: 0.31419286131858826\n",
            "Batch: 1600, Average Loss: 0.31390416622161865\n",
            "Batch: 1700, Average Loss: 0.31426358222961426\n",
            "Batch: 1800, Average Loss: 0.31382885575294495\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.2708704471588135\n",
            "Batch: 100, Average Loss: 0.3058508634567261\n",
            "Batch: 200, Average Loss: 0.29929977655410767\n",
            "Batch: 300, Average Loss: 0.29679012298583984\n",
            "Batch: 400, Average Loss: 0.28657087683677673\n",
            "Batch: 500, Average Loss: 0.28715217113494873\n",
            "Batch: 600, Average Loss: 0.29077160358428955\n",
            "Batch: 700, Average Loss: 0.2896287739276886\n",
            "Batch: 800, Average Loss: 0.2905338406562805\n",
            "Batch: 900, Average Loss: 0.2872193455696106\n",
            "Batch: 1000, Average Loss: 0.28585246205329895\n",
            "Batch: 1100, Average Loss: 0.284334272146225\n",
            "Batch: 1200, Average Loss: 0.2845035791397095\n",
            "Batch: 1300, Average Loss: 0.2833453118801117\n",
            "Batch: 1400, Average Loss: 0.282476007938385\n",
            "Batch: 1500, Average Loss: 0.28261277079582214\n",
            "Batch: 1600, Average Loss: 0.2825145125389099\n",
            "Batch: 1700, Average Loss: 0.28304794430732727\n",
            "Batch: 1800, Average Loss: 0.2825835347175598\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.25757092237472534\n",
            "Batch: 100, Average Loss: 0.28216609358787537\n",
            "Batch: 200, Average Loss: 0.27800634503364563\n",
            "Batch: 300, Average Loss: 0.2737848460674286\n",
            "Batch: 400, Average Loss: 0.2637273967266083\n",
            "Batch: 500, Average Loss: 0.26517581939697266\n",
            "Batch: 600, Average Loss: 0.2684248387813568\n",
            "Batch: 700, Average Loss: 0.2669508457183838\n",
            "Batch: 800, Average Loss: 0.26774778962135315\n",
            "Batch: 900, Average Loss: 0.2649547755718231\n",
            "Batch: 1000, Average Loss: 0.2637643814086914\n",
            "Batch: 1100, Average Loss: 0.26227203011512756\n",
            "Batch: 1200, Average Loss: 0.26209333539009094\n",
            "Batch: 1300, Average Loss: 0.26085758209228516\n",
            "Batch: 1400, Average Loss: 0.26022103428840637\n",
            "Batch: 1500, Average Loss: 0.2603183090686798\n",
            "Batch: 1600, Average Loss: 0.2599111497402191\n",
            "Batch: 1700, Average Loss: 0.26052236557006836\n",
            "Batch: 1800, Average Loss: 0.26015162467956543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.2604154348373413</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 12.002044677734375\n",
            "Batch: 100, Average Loss: 3.4123358726501465\n",
            "Batch: 200, Average Loss: 2.1059823036193848\n",
            "Batch: 300, Average Loss: 1.6015771627426147\n",
            "Batch: 400, Average Loss: 1.3265650272369385\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.3937363624572754\n",
            "Batch: 100, Average Loss: 0.4418632686138153\n",
            "Batch: 200, Average Loss: 0.44190698862075806\n",
            "Batch: 300, Average Loss: 0.42535871267318726\n",
            "Batch: 400, Average Loss: 0.4124586582183838\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.2716245651245117\n",
            "Batch: 100, Average Loss: 0.35612383484840393\n",
            "Batch: 200, Average Loss: 0.3602593243122101\n",
            "Batch: 300, Average Loss: 0.3517549932003021\n",
            "Batch: 400, Average Loss: 0.3448539078235626\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.21671278774738312\n",
            "Batch: 100, Average Loss: 0.3120724558830261\n",
            "Batch: 200, Average Loss: 0.3170376420021057\n",
            "Batch: 300, Average Loss: 0.31087231636047363\n",
            "Batch: 400, Average Loss: 0.3065994083881378\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.18468746542930603\n",
            "Batch: 100, Average Loss: 0.28293338418006897\n",
            "Batch: 200, Average Loss: 0.28741455078125\n",
            "Batch: 300, Average Loss: 0.28211647272109985\n",
            "Batch: 400, Average Loss: 0.2788051962852478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 128</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 120</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.2784186899662018</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 12.624363899230957\n",
            "Batch: 100, Average Loss: 3.4828741550445557\n",
            "Batch: 200, Average Loss: 2.172593355178833\n",
            "Batch: 300, Average Loss: 1.6649309396743774\n",
            "Batch: 400, Average Loss: 1.382293939590454\n",
            "Batch: 500, Average Loss: 1.2069162130355835\n",
            "Batch: 600, Average Loss: 1.0876576900482178\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.3547945022583008\n",
            "Batch: 100, Average Loss: 0.4377260208129883\n",
            "Batch: 200, Average Loss: 0.43394362926483154\n",
            "Batch: 300, Average Loss: 0.4197690784931183\n",
            "Batch: 400, Average Loss: 0.4107525944709778\n",
            "Batch: 500, Average Loss: 0.4029659926891327\n",
            "Batch: 600, Average Loss: 0.39871713519096375\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.25154557824134827\n",
            "Batch: 100, Average Loss: 0.34673815965652466\n",
            "Batch: 200, Average Loss: 0.34980693459510803\n",
            "Batch: 300, Average Loss: 0.34260690212249756\n",
            "Batch: 400, Average Loss: 0.3377698063850403\n",
            "Batch: 500, Average Loss: 0.3323744833469391\n",
            "Batch: 600, Average Loss: 0.33151158690452576\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.1916402131319046\n",
            "Batch: 100, Average Loss: 0.3019513189792633\n",
            "Batch: 200, Average Loss: 0.3054846525192261\n",
            "Batch: 300, Average Loss: 0.30002260208129883\n",
            "Batch: 400, Average Loss: 0.29690995812416077\n",
            "Batch: 500, Average Loss: 0.2924068570137024\n",
            "Batch: 600, Average Loss: 0.29256173968315125\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.15626205503940582\n",
            "Batch: 100, Average Loss: 0.2705615162849426\n",
            "Batch: 200, Average Loss: 0.2755540609359741\n",
            "Batch: 300, Average Loss: 0.27095410227775574\n",
            "Batch: 400, Average Loss: 0.26847973465919495\n",
            "Batch: 500, Average Loss: 0.2648810148239136\n",
            "Batch: 600, Average Loss: 0.26545584201812744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 96</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 180</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.2654280662536621</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 7.406989574432373\n",
            "Batch: 100, Average Loss: 2.6277694702148438\n",
            "Batch: 200, Average Loss: 1.8220843076705933\n",
            "Batch: 300, Average Loss: 1.4537571668624878\n",
            "Batch: 400, Average Loss: 1.2393184900283813\n",
            "Batch: 500, Average Loss: 1.1023956537246704\n",
            "Batch: 600, Average Loss: 1.0117313861846924\n",
            "Batch: 700, Average Loss: 0.9365993738174438\n",
            "Batch: 800, Average Loss: 0.8826814293861389\n",
            "Batch: 900, Average Loss: 0.8366691470146179\n",
            "Batch: 1000, Average Loss: 0.7975728511810303\n",
            "Batch: 1100, Average Loss: 0.7649135589599609\n",
            "Batch: 1200, Average Loss: 0.7388320565223694\n",
            "Batch: 1300, Average Loss: 0.7148988842964172\n",
            "Batch: 1400, Average Loss: 0.6933408379554749\n",
            "Batch: 1500, Average Loss: 0.6758251190185547\n",
            "Batch: 1600, Average Loss: 0.6600152850151062\n",
            "Batch: 1700, Average Loss: 0.6474039554595947\n",
            "Batch: 1800, Average Loss: 0.634393036365509\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.41277459263801575\n",
            "Batch: 100, Average Loss: 0.40757426619529724\n",
            "Batch: 200, Average Loss: 0.39314547181129456\n",
            "Batch: 300, Average Loss: 0.385124146938324\n",
            "Batch: 400, Average Loss: 0.37400004267692566\n",
            "Batch: 500, Average Loss: 0.37209492921829224\n",
            "Batch: 600, Average Loss: 0.37307748198509216\n",
            "Batch: 700, Average Loss: 0.3688446283340454\n",
            "Batch: 800, Average Loss: 0.3671067953109741\n",
            "Batch: 900, Average Loss: 0.3640054166316986\n",
            "Batch: 1000, Average Loss: 0.36156022548675537\n",
            "Batch: 1100, Average Loss: 0.35891708731651306\n",
            "Batch: 1200, Average Loss: 0.3586554229259491\n",
            "Batch: 1300, Average Loss: 0.3567022681236267\n",
            "Batch: 1400, Average Loss: 0.35457664728164673\n",
            "Batch: 1500, Average Loss: 0.35360944271087646\n",
            "Batch: 1600, Average Loss: 0.3526558578014374\n",
            "Batch: 1700, Average Loss: 0.3535371422767639\n",
            "Batch: 1800, Average Loss: 0.35297784209251404\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.24388918280601501\n",
            "Batch: 100, Average Loss: 0.33935147523880005\n",
            "Batch: 200, Average Loss: 0.32636168599128723\n",
            "Batch: 300, Average Loss: 0.3203738331794739\n",
            "Batch: 400, Average Loss: 0.3125438392162323\n",
            "Batch: 500, Average Loss: 0.31326037645339966\n",
            "Batch: 600, Average Loss: 0.3146572709083557\n",
            "Batch: 700, Average Loss: 0.31135523319244385\n",
            "Batch: 800, Average Loss: 0.3097425103187561\n",
            "Batch: 900, Average Loss: 0.30688798427581787\n",
            "Batch: 1000, Average Loss: 0.3060949146747589\n",
            "Batch: 1100, Average Loss: 0.30421140789985657\n",
            "Batch: 1200, Average Loss: 0.30434224009513855\n",
            "Batch: 1300, Average Loss: 0.303427517414093\n",
            "Batch: 1400, Average Loss: 0.3017980754375458\n",
            "Batch: 1500, Average Loss: 0.3018206059932709\n",
            "Batch: 1600, Average Loss: 0.3012048304080963\n",
            "Batch: 1700, Average Loss: 0.3025098145008087\n",
            "Batch: 1800, Average Loss: 0.30235448479652405\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.20598189532756805\n",
            "Batch: 100, Average Loss: 0.3052665889263153\n",
            "Batch: 200, Average Loss: 0.29150038957595825\n",
            "Batch: 300, Average Loss: 0.28430116176605225\n",
            "Batch: 400, Average Loss: 0.2763199806213379\n",
            "Batch: 500, Average Loss: 0.2784579396247864\n",
            "Batch: 600, Average Loss: 0.27906832098960876\n",
            "Batch: 700, Average Loss: 0.2769553065299988\n",
            "Batch: 800, Average Loss: 0.2760660648345947\n",
            "Batch: 900, Average Loss: 0.2733943462371826\n",
            "Batch: 1000, Average Loss: 0.2730989456176758\n",
            "Batch: 1100, Average Loss: 0.2715938687324524\n",
            "Batch: 1200, Average Loss: 0.2719859182834625\n",
            "Batch: 1300, Average Loss: 0.27165520191192627\n",
            "Batch: 1400, Average Loss: 0.2702711522579193\n",
            "Batch: 1500, Average Loss: 0.27101123332977295\n",
            "Batch: 1600, Average Loss: 0.2703966200351715\n",
            "Batch: 1700, Average Loss: 0.2715708911418915\n",
            "Batch: 1800, Average Loss: 0.27178436517715454\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.18743857741355896\n",
            "Batch: 100, Average Loss: 0.27981114387512207\n",
            "Batch: 200, Average Loss: 0.2631712853908539\n",
            "Batch: 300, Average Loss: 0.25728076696395874\n",
            "Batch: 400, Average Loss: 0.2498777061700821\n",
            "Batch: 500, Average Loss: 0.2521849274635315\n",
            "Batch: 600, Average Loss: 0.25304678082466125\n",
            "Batch: 700, Average Loss: 0.25224804878234863\n",
            "Batch: 800, Average Loss: 0.2514432370662689\n",
            "Batch: 900, Average Loss: 0.24884115159511566\n",
            "Batch: 1000, Average Loss: 0.24931937456130981\n",
            "Batch: 1100, Average Loss: 0.24800533056259155\n",
            "Batch: 1200, Average Loss: 0.2481466382741928\n",
            "Batch: 1300, Average Loss: 0.24772551655769348\n",
            "Batch: 1400, Average Loss: 0.2465362697839737\n",
            "Batch: 1500, Average Loss: 0.24737221002578735\n",
            "Batch: 1600, Average Loss: 0.24692542850971222\n",
            "Batch: 1700, Average Loss: 0.24822625517845154\n",
            "Batch: 1800, Average Loss: 0.24862481653690338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 160</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 180</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.24879196286201477</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 8.54290771484375\n",
            "Batch: 100, Average Loss: 2.6425113677978516\n",
            "Batch: 200, Average Loss: 1.7689409255981445\n",
            "Batch: 300, Average Loss: 1.412920355796814\n",
            "Batch: 400, Average Loss: 1.2085230350494385\n",
            "Batch: 500, Average Loss: 1.0724027156829834\n",
            "Batch: 600, Average Loss: 0.9810242652893066\n",
            "Batch: 700, Average Loss: 0.9054693579673767\n",
            "Batch: 800, Average Loss: 0.851116955280304\n",
            "Batch: 900, Average Loss: 0.8069913983345032\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.33755505084991455\n",
            "Batch: 100, Average Loss: 0.42674216628074646\n",
            "Batch: 200, Average Loss: 0.42069703340530396\n",
            "Batch: 300, Average Loss: 0.42093464732170105\n",
            "Batch: 400, Average Loss: 0.41440480947494507\n",
            "Batch: 500, Average Loss: 0.4061152935028076\n",
            "Batch: 600, Average Loss: 0.4033909738063812\n",
            "Batch: 700, Average Loss: 0.396137535572052\n",
            "Batch: 800, Average Loss: 0.39171668887138367\n",
            "Batch: 900, Average Loss: 0.388923317193985\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.27991724014282227\n",
            "Batch: 100, Average Loss: 0.3504788279533386\n",
            "Batch: 200, Average Loss: 0.34670862555503845\n",
            "Batch: 300, Average Loss: 0.34911102056503296\n",
            "Batch: 400, Average Loss: 0.3457842171192169\n",
            "Batch: 500, Average Loss: 0.34020107984542847\n",
            "Batch: 600, Average Loss: 0.33936527371406555\n",
            "Batch: 700, Average Loss: 0.3347831666469574\n",
            "Batch: 800, Average Loss: 0.33206093311309814\n",
            "Batch: 900, Average Loss: 0.3313641846179962\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.22105666995048523\n",
            "Batch: 100, Average Loss: 0.3092547357082367\n",
            "Batch: 200, Average Loss: 0.30597612261772156\n",
            "Batch: 300, Average Loss: 0.3083232343196869\n",
            "Batch: 400, Average Loss: 0.30625858902931213\n",
            "Batch: 500, Average Loss: 0.30176424980163574\n",
            "Batch: 600, Average Loss: 0.3016560971736908\n",
            "Batch: 700, Average Loss: 0.2983740270137787\n",
            "Batch: 800, Average Loss: 0.29613369703292847\n",
            "Batch: 900, Average Loss: 0.2962920367717743\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.20400547981262207\n",
            "Batch: 100, Average Loss: 0.28027844429016113\n",
            "Batch: 200, Average Loss: 0.27711039781570435\n",
            "Batch: 300, Average Loss: 0.27940788865089417\n",
            "Batch: 400, Average Loss: 0.27813521027565\n",
            "Batch: 500, Average Loss: 0.274225115776062\n",
            "Batch: 600, Average Loss: 0.2743105888366699\n",
            "Batch: 700, Average Loss: 0.27178072929382324\n",
            "Batch: 800, Average Loss: 0.26979440450668335\n",
            "Batch: 900, Average Loss: 0.2702861726284027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 64</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 140</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.27023929357528687</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Batch: 0, Average Loss: 13.76427936553955\n",
            "Batch: 100, Average Loss: 3.3301842212677\n",
            "Batch: 200, Average Loss: 2.253934144973755\n",
            "Batch: 300, Average Loss: 1.7480144500732422\n",
            "Batch: 400, Average Loss: 1.461559534072876\n",
            "Batch: 500, Average Loss: 1.276032567024231\n",
            "Batch: 600, Average Loss: 1.1519694328308105\n",
            "Batch: 700, Average Loss: 1.0582306385040283\n",
            "Batch: 800, Average Loss: 0.9883582592010498\n",
            "Batch: 900, Average Loss: 0.929518461227417\n",
            "Batch: 1000, Average Loss: 0.8801169395446777\n",
            "Batch: 1100, Average Loss: 0.8408903479576111\n",
            "Batch: 1200, Average Loss: 0.8088165521621704\n",
            "Batch: 1300, Average Loss: 0.779218852519989\n",
            "Batch: 1400, Average Loss: 0.7531381249427795\n",
            "Batch: 1500, Average Loss: 0.7313189506530762\n",
            "Batch: 1600, Average Loss: 0.7119705080986023\n",
            "Batch: 1700, Average Loss: 0.6959987282752991\n",
            "Batch: 1800, Average Loss: 0.6804043054580688\n",
            "Epoch: 1\n",
            "Batch: 0, Average Loss: 0.2297326624393463\n",
            "Batch: 100, Average Loss: 0.4054342210292816\n",
            "Batch: 200, Average Loss: 0.3902331590652466\n",
            "Batch: 300, Average Loss: 0.38948845863342285\n",
            "Batch: 400, Average Loss: 0.3788094222545624\n",
            "Batch: 500, Average Loss: 0.3764438331127167\n",
            "Batch: 600, Average Loss: 0.37701231241226196\n",
            "Batch: 700, Average Loss: 0.37216514348983765\n",
            "Batch: 800, Average Loss: 0.36902397871017456\n",
            "Batch: 900, Average Loss: 0.36430469155311584\n",
            "Batch: 1000, Average Loss: 0.36126968264579773\n",
            "Batch: 1100, Average Loss: 0.3588130474090576\n",
            "Batch: 1200, Average Loss: 0.35881781578063965\n",
            "Batch: 1300, Average Loss: 0.35720574855804443\n",
            "Batch: 1400, Average Loss: 0.35427770018577576\n",
            "Batch: 1500, Average Loss: 0.35338929295539856\n",
            "Batch: 1600, Average Loss: 0.3523644208908081\n",
            "Batch: 1700, Average Loss: 0.35243865847587585\n",
            "Batch: 1800, Average Loss: 0.3522365987300873\n",
            "Epoch: 2\n",
            "Batch: 0, Average Loss: 0.15460774302482605\n",
            "Batch: 100, Average Loss: 0.3374578356742859\n",
            "Batch: 200, Average Loss: 0.32145798206329346\n",
            "Batch: 300, Average Loss: 0.3203919529914856\n",
            "Batch: 400, Average Loss: 0.31338098645210266\n",
            "Batch: 500, Average Loss: 0.311625212430954\n",
            "Batch: 600, Average Loss: 0.31370043754577637\n",
            "Batch: 700, Average Loss: 0.3110120892524719\n",
            "Batch: 800, Average Loss: 0.3100413680076599\n",
            "Batch: 900, Average Loss: 0.3071635961532593\n",
            "Batch: 1000, Average Loss: 0.3058871924877167\n",
            "Batch: 1100, Average Loss: 0.30440133810043335\n",
            "Batch: 1200, Average Loss: 0.30434346199035645\n",
            "Batch: 1300, Average Loss: 0.3032799959182739\n",
            "Batch: 1400, Average Loss: 0.3016836941242218\n",
            "Batch: 1500, Average Loss: 0.30120399594306946\n",
            "Batch: 1600, Average Loss: 0.3005417287349701\n",
            "Batch: 1700, Average Loss: 0.3009719252586365\n",
            "Batch: 1800, Average Loss: 0.3014928996562958\n",
            "Epoch: 3\n",
            "Batch: 0, Average Loss: 0.14947102963924408\n",
            "Batch: 100, Average Loss: 0.2971627712249756\n",
            "Batch: 200, Average Loss: 0.2826424241065979\n",
            "Batch: 300, Average Loss: 0.2826775014400482\n",
            "Batch: 400, Average Loss: 0.2770662009716034\n",
            "Batch: 500, Average Loss: 0.2762680649757385\n",
            "Batch: 600, Average Loss: 0.27843645215034485\n",
            "Batch: 700, Average Loss: 0.2765069007873535\n",
            "Batch: 800, Average Loss: 0.2754287123680115\n",
            "Batch: 900, Average Loss: 0.2725679278373718\n",
            "Batch: 1000, Average Loss: 0.27196913957595825\n",
            "Batch: 1100, Average Loss: 0.27114659547805786\n",
            "Batch: 1200, Average Loss: 0.2709033191204071\n",
            "Batch: 1300, Average Loss: 0.2699643671512604\n",
            "Batch: 1400, Average Loss: 0.2688210606575012\n",
            "Batch: 1500, Average Loss: 0.268585741519928\n",
            "Batch: 1600, Average Loss: 0.26791462302207947\n",
            "Batch: 1700, Average Loss: 0.26872894167900085\n",
            "Batch: 1800, Average Loss: 0.2696438729763031\n",
            "Epoch: 4\n",
            "Batch: 0, Average Loss: 0.13788223266601562\n",
            "Batch: 100, Average Loss: 0.26991593837738037\n",
            "Batch: 200, Average Loss: 0.25771957635879517\n",
            "Batch: 300, Average Loss: 0.25718629360198975\n",
            "Batch: 400, Average Loss: 0.25186532735824585\n",
            "Batch: 500, Average Loss: 0.25165829062461853\n",
            "Batch: 600, Average Loss: 0.25272125005722046\n",
            "Batch: 700, Average Loss: 0.2511416971683502\n",
            "Batch: 800, Average Loss: 0.2506583034992218\n",
            "Batch: 900, Average Loss: 0.24786245822906494\n",
            "Batch: 1000, Average Loss: 0.24760368466377258\n",
            "Batch: 1100, Average Loss: 0.2470262199640274\n",
            "Batch: 1200, Average Loss: 0.2469819039106369\n",
            "Batch: 1300, Average Loss: 0.24632886052131653\n",
            "Batch: 1400, Average Loss: 0.24542859196662903\n",
            "Batch: 1500, Average Loss: 0.24556171894073486\n",
            "Batch: 1600, Average Loss: 0.24477963149547577\n",
            "Batch: 1700, Average Loss: 0.24579156935214996\n",
            "Batch: 1800, Average Loss: 0.24679172039031982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hp values:</h2></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-batch_size: 32</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:blue\"> |-nou: 200</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-nou_w: 200</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Score: 0.24708855152130127</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Best step: 4</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOjtWHN8Z_YC"
      },
      "source": [
        "m = tuner.get_best_models()[0]"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbMMMjJ-a9PF",
        "outputId": "6b867324-367b-49c8-939f-9f97c04b00aa"
      },
      "source": [
        "k = 0\n",
        "for i in dataset:\n",
        "  #print(i[1])\n",
        "  print('REAL -> {}'.format(np.argmax(i[1])))\n",
        "  pred = m(i[0][np.newaxis,:])\n",
        "  print('PRED -> {}'.format(np.argmax(pred,axis = 1)))\n",
        "  k+=1\n",
        "  if k==50:\n",
        "    break\n"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REAL -> 9\n",
            "PRED -> [9]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n",
            "REAL -> 0\n",
            "PRED -> [3]\n",
            "REAL -> 2\n",
            "PRED -> [2]\n",
            "REAL -> 7\n",
            "PRED -> [7]\n",
            "REAL -> 2\n",
            "PRED -> [2]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 9\n",
            "PRED -> [9]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 7\n",
            "PRED -> [7]\n",
            "REAL -> 9\n",
            "PRED -> [9]\n",
            "REAL -> 1\n",
            "PRED -> [1]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 6\n",
            "PRED -> [6]\n",
            "REAL -> 4\n",
            "PRED -> [4]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n",
            "REAL -> 1\n",
            "PRED -> [1]\n",
            "REAL -> 4\n",
            "PRED -> [4]\n",
            "REAL -> 8\n",
            "PRED -> [8]\n",
            "REAL -> 4\n",
            "PRED -> [2]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 2\n",
            "PRED -> [2]\n",
            "REAL -> 4\n",
            "PRED -> [4]\n",
            "REAL -> 4\n",
            "PRED -> [4]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n",
            "REAL -> 6\n",
            "PRED -> [6]\n",
            "REAL -> 6\n",
            "PRED -> [6]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 8\n",
            "PRED -> [8]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 2\n",
            "PRED -> [2]\n",
            "REAL -> 1\n",
            "PRED -> [1]\n",
            "REAL -> 6\n",
            "PRED -> [6]\n",
            "REAL -> 6\n",
            "PRED -> [6]\n",
            "REAL -> 7\n",
            "PRED -> [7]\n",
            "REAL -> 9\n",
            "PRED -> [9]\n",
            "REAL -> 5\n",
            "PRED -> [5]\n",
            "REAL -> 9\n",
            "PRED -> [9]\n",
            "REAL -> 2\n",
            "PRED -> [2]\n",
            "REAL -> 7\n",
            "PRED -> [7]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n",
            "REAL -> 0\n",
            "PRED -> [0]\n",
            "REAL -> 3\n",
            "PRED -> [3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzkSHvqDbQ61",
        "outputId": "29fe987f-3e16-4982-bcf6-362e8f8dea1a"
      },
      "source": [
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "print(best_hps.values)"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nou': 200, 'nou_w': 160, 'batch_size': 96}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL1WrSpoco9z",
        "outputId": "3996aa60-0352-4a1a-ba64-29a880993f8a"
      },
      "source": [
        "for i in tuner.get_best_hyperparameters(num_trials = 10):\n",
        "  print(i.values)"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'nou': 200, 'nou_w': 160, 'batch_size': 96}\n",
            "{'nou': 200, 'nou_w': 200, 'batch_size': 32}\n",
            "{'nou': 200, 'nou_w': 140, 'batch_size': 64}\n",
            "{'nou': 160, 'nou_w': 180, 'batch_size': 32}\n",
            "{'nou': 160, 'nou_w': 140, 'batch_size': 32}\n",
            "{'nou': 140, 'nou_w': 160, 'batch_size': 96}\n",
            "{'nou': 140, 'nou_w': 180, 'batch_size': 96}\n",
            "{'nou': 160, 'nou_w': 160, 'batch_size': 96}\n",
            "{'nou': 140, 'nou_w': 140, 'batch_size': 64}\n",
            "{'nou': 120, 'nou_w': 160, 'batch_size': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "PMZtPozndiTn",
        "outputId": "c3b6e321-da93-4fc6-f195-081120f7611f"
      },
      "source": [
        "tuner.results_summary()\n"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Results in results/mnist_custom_training</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.24260877072811127</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.24708855152130127</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.2471131831407547</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.24879196286201477</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.2604154348373413</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.26329633593559265</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.2654280662536621</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.26550161838531494</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.27023929357528687</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span style=\"color:cyan\"> |-Objective: Objective(name='fin_loss', direction='min') Score: 0.2784186899662018</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwO4O6qZdtWn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}